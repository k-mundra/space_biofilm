{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00707c6a"
      },
      "source": [
        "\n",
        "# Ground→Space Trajectory Modeling (Microscopy + Optional RNA Auxiliary Head)\n",
        "\n",
        "This extension adapts the existing ConvLSTM tutorial to your dataset layout:\n",
        "- TIFF microscopy stacks per sample/timepoint\n",
        "- Optional RNA features (when available) used via an auxiliary head\n",
        "- Trajectory construction grouped by `(Spaceflight, Material, Medium)`, sorted by `Time`\n",
        "- Primary objective: predict **Space** trajectories **from Ground** trajectories\n",
        "\n",
        "> If `s_OSD-627.txt` is provided, the parser below will extract `(Spaceflight, Material, Medium, Time, SampleID)` for clean trajectory linking. If not provided, we fall back to the provided manifest CSVs to align images and RNA columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "57a70898"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Setup & Imports ---\n",
        "import os, re, json, zipfile, io\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    import tifffile as tiff\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"tifffile is required. Please install via pip if missing.\") from e\n",
        "\n",
        "# Torch is optional at load time; only required for the model/training section\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "except Exception as e:\n",
        "    print(\"Note: PyTorch not found at import time. You can still run preprocessing and mapping.\")\n",
        "\n",
        "INPUT_ZIP  = Path(\"microscopy.zip\")      # your original\n",
        "OUTPUT_ZIP = Path(\"microscopy_ds.zip\")   # where to write downsampled tiffs\n",
        "DOWNSAMPLE = 2     # integer factor (2, 3, 4, ...) — uses stride decimation (fast & low RAM)\n",
        "COMPRESSION = 'deflate'  # 'deflate' (zlib), 'lzma', or None\n",
        "DATA_DIR_RNA = Path(\"Normalized_counts\")\n",
        "# Expected optional files:\n",
        "# S_OSD_TXT = DATA_DIR / \"s_OSD-627.txt\"  # Provide this to unlock full parser\n",
        "S_OSD_TXT = Path(\"s_OSD-627.txt\")\n",
        "MANIFEST_CSV = Path(\"updates_manifest.tsv\")\n",
        "PROVISIONAL_CSV = Path(\"Provisional_image_RNA_manifest__edit__chosen_rna_col__later_.csv\")\n",
        "\n",
        "# Example RNA xlsx (already uploaded) – update/extend as you add the rest:\n",
        "RNA_SHEETS = [\n",
        "    DATA_DIR_RNA / \"SSMicro_day1v3_bytime.xlsx\",\n",
        "    DATA_DIR_RNA / \"SSGround_day1v3_bytime.xlsx\",\n",
        "    DATA_DIR_RNA / \"SS_day3_bygravity.xlsx\",\n",
        "    DATA_DIR_RNA / \"Micro_day3_bymaterial.xlsx\",\n",
        "    DATA_DIR_RNA / \"LIS_day3_bygravity.xlsx\",\n",
        "    DATA_DIR_RNA / \"Ground_day3_bymaterial.xlsx\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gFnRAthuqWO",
        "outputId": "f315a753-0f96-4d7c-f13a-f0b46038d776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 479 TIFFs\n",
            "Processed 10/479 …\n",
            "Processed 20/479 …\n",
            "Processed 30/479 …\n",
            "Processed 40/479 …\n",
            "Processed 50/479 …\n",
            "Processed 60/479 …\n",
            "Processed 70/479 …\n",
            "Processed 80/479 …\n",
            "Processed 90/479 …\n",
            "Processed 100/479 …\n",
            "Processed 110/479 …\n",
            "Processed 120/479 …\n",
            "Processed 130/479 …\n",
            "Processed 140/479 …\n",
            "Processed 150/479 …\n",
            "Processed 160/479 …\n",
            "Processed 170/479 …\n",
            "Processed 180/479 …\n",
            "Processed 190/479 …\n",
            "Processed 200/479 …\n",
            "Processed 210/479 …\n",
            "Processed 220/479 …\n",
            "Processed 230/479 …\n",
            "Processed 240/479 …\n",
            "Processed 250/479 …\n",
            "Processed 260/479 …\n",
            "Processed 270/479 …\n",
            "Processed 280/479 …\n",
            "Processed 290/479 …\n",
            "Processed 300/479 …\n",
            "Processed 310/479 …\n",
            "Processed 320/479 …\n",
            "Processed 330/479 …\n",
            "Processed 340/479 …\n",
            "Processed 350/479 …\n",
            "Processed 360/479 …\n",
            "Processed 370/479 …\n",
            "Processed 380/479 …\n",
            "Processed 390/479 …\n",
            "Processed 400/479 …\n",
            "Processed 410/479 …\n",
            "Processed 420/479 …\n",
            "Processed 430/479 …\n",
            "Processed 440/479 …\n",
            "Processed 450/479 …\n",
            "Processed 460/479 …\n",
            "Processed 470/479 …\n",
            "Done. Skipped: 0\n"
          ]
        }
      ],
      "source": [
        "# def _decimate(arr, factor):\n",
        "#     \"\"\"Fast, low-memory decimation by integer factor (area-shrink alternative without deps).\"\"\"\n",
        "#     if arr.ndim == 2:        # [H,W]\n",
        "#         return arr[::factor, ::factor]\n",
        "#     elif arr.ndim == 3:\n",
        "#         # We assume grayscale stack [T,H,W] (your case). If it's RGB per frame, see note below.\n",
        "#         return arr[:, ::factor, ::factor]\n",
        "#     else:\n",
        "#         # squeeze and try again\n",
        "#         arr2 = np.squeeze(arr)\n",
        "#         if arr2.ndim in (2,3):\n",
        "#             return _decimate(arr2, factor)\n",
        "#         raise ValueError(f\"Unexpected array shape {arr.shape}\")\n",
        "\n",
        "# def _ensure_stack_THW(arr):\n",
        "#     \"\"\"Return [T,H,W] float32.\"\"\"\n",
        "#     arr = np.asarray(arr)\n",
        "#     if arr.ndim == 2:    # [H,W]\n",
        "#         arr = arr[None, ...]\n",
        "#     elif arr.ndim != 3:\n",
        "#         arr = np.squeeze(arr)\n",
        "#         if arr.ndim == 2:\n",
        "#             arr = arr[None, ...]\n",
        "#         elif arr.ndim != 3:\n",
        "#             raise ValueError(f\"Cannot coerce shape {arr.shape} to [T,H,W]\")\n",
        "#     return arr.astype(np.float32, copy=False)\n",
        "\n",
        "# def downsample_tiff_bytes(in_bytes, factor, compression=COMPRESSION):\n",
        "#     \"\"\"\n",
        "#     Read a TIFF from bytes, downsample frame-by-frame by integer factor,\n",
        "#     and return new TIFF bytes (compressed).\n",
        "#     Uses streaming write to keep memory low.\n",
        "#     \"\"\"\n",
        "#     out_buf = io.BytesIO()\n",
        "#     with tiff.TiffFile(io.BytesIO(in_bytes)) as tf, tiff.TiffWriter(out_buf, bigtiff=True) as tw:\n",
        "    #     # Try to iterate by TIFF pages/series to avoid loading entire stacks\n",
        "    #     # Many microscopy stacks expose a single series with multiple pages (frames)\n",
        "    #     series = tf.series[0]\n",
        "    #     # When the series is paged, iterate pages; else fall back to asarray()\n",
        "    #     if len(series.pages) > 1:\n",
        "    #         for page in series.pages:\n",
        "    #             frame = page.asarray()          # [H,W] (expected grayscale)\n",
        "    #             frame = _decimate(frame, factor)\n",
        "    #             tw.write(\n",
        "    #                 frame.astype(np.float32),\n",
        "    #                 photometric='minisblack',\n",
        "    #                 compression=compression\n",
        "    #             )\n",
        "    #     else:\n",
        "    #         # Single array; could be [T,H,W] or [H,W]\n",
        "    #         arr = _ensure_stack_THW(series.asarray())\n",
        "    #         arr_ds = _decimate(arr, factor)    # [T,H',W']\n",
        "    #         # Write as multi-page TIFF\n",
        "    #         for t in range(arr_ds.shape[0]):\n",
        "    #             tw.write(\n",
        "    #                 arr_ds[t].astype(np.float32),\n",
        "    #                 photometric='minisblack',\n",
        "    #                 compression=compression\n",
        "    #             )\n",
        "    # out_buf.seek(0)\n",
        "    # return out_buf.read()\n",
        "\n",
        "# def _is_tiff_magic(b4: bytes) -> bool:\n",
        "#     return b4 in (b'II*\\x00', b'MM\\x00*', b'II+\\x00', b'MM\\x00+')\n",
        "\n",
        "# # Process all TIFFs in the input zip and write downsampled versions to output zip\n",
        "# assert INPUT_ZIP.exists(), f\"Missing {INPUT_ZIP}\"\n",
        "# with zipfile.ZipFile(INPUT_ZIP, \"r\") as zin, zipfile.ZipFile(OUTPUT_ZIP, \"w\", compression=zipfile.ZIP_STORED) as zout:\n",
        "#     names = [n for n in zin.namelist()\n",
        "#              if n.lower().endswith((\".tif\", \".tiff\"))\n",
        "#              and not n.endswith(\"/\")\n",
        "#              and not n.startswith(\"__MACOSX/\")]\n",
        "#     print(f\"Found {len(names)} TIFF-like entries\")\n",
        "#     skipped = 0\n",
        "#     for i, name in enumerate(sorted(names)):\n",
        "#         with zin.open(name) as f:\n",
        "#             head = f.read(4)\n",
        "#             if not _is_tiff_magic(head):\n",
        "#                 skipped += 1\n",
        "#                 continue\n",
        "#             data = head + f.read()\n",
        "\n",
        "#         try:\n",
        "#             ds_bytes = downsample_tiff_bytes(data, DOWNSAMPLE, compression=COMPRESSION)\n",
        "#             # Write to zip with same relative name (you can prefix if you want)\n",
        "#             zout.writestr(name, ds_bytes)\n",
        "#         except Exception as e:\n",
        "#             skipped += 1\n",
        "#             print(f\"[skip] {name}: {e}\")\n",
        "#             continue\n",
        "\n",
        "#         if (i+1) % 10 == 0:\n",
        "#             print(f\"Processed {i+1}/{len(names)}...\")\n",
        "\n",
        "# print(f\"Done. Wrote downsampled TIFFs to {OUTPUT_ZIP}. Skipped {skipped} items.\")\n",
        "\n",
        "# ===============================================\n",
        "# NEW TIFF → PNG MERGE + PNG TILING PIPELINE\n",
        "# ===============================================\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# -------- TIFF → single PNG (combine z-layers) --------\n",
        "\n",
        "def combine_tiff_layers_to_png(tiff_path, output_png):\n",
        "    \"\"\"\n",
        "    Combine all layers of a multi-layer TIFF into a single PNG.\n",
        "    Uses max projection (recommended for confocal morphology).\n",
        "    \"\"\"\n",
        "    tiff = Image.open(tiff_path)\n",
        "\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            frame = np.array(tiff.convert(\"L\"), dtype=np.float32)\n",
        "            frames.append(frame)\n",
        "            tiff.seek(tiff.tell() + 1)\n",
        "    except EOFError:\n",
        "        pass\n",
        "\n",
        "    if len(frames) == 0:\n",
        "        raise ValueError(f\"No frames found in TIFF: {tiff_path}\")\n",
        "\n",
        "    # max projection across Z\n",
        "    combined = np.max(frames, axis=0)\n",
        "    combined = np.clip(combined, 0, 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(combined).save(output_png)\n",
        "\n",
        "# -------- Resize + tile PNGs --------\n",
        "\n",
        "def resize_to_512(img):\n",
        "    return img.resize((512, 512), Image.LANCZOS)\n",
        "\n",
        "def split_image(img, n):\n",
        "    tiles = []\n",
        "    w, h = img.size\n",
        "    tile_w = w // n\n",
        "    tile_h = h // n\n",
        "    for r in range(n):\n",
        "        for c in range(n):\n",
        "            box = (c*tile_w, r*tile_h, (c+1)*tile_w, (r+1)*tile_h)\n",
        "            tiles.append(img.crop(box))\n",
        "    return tiles\n",
        "\n",
        "def process_png_folder(input_folder, output_folder, n=2):\n",
        "    \"\"\"\n",
        "    Reads processed PNGs (generated from TIFF).\n",
        "    Resizes each to 512x512.\n",
        "    Splits into NxN tiles.\n",
        "    Saves tiles with suffix _01, _02, ...\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for fname in os.listdir(input_folder):\n",
        "        if not fname.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(os.path.join(input_folder, fname))\n",
        "        img = resize_to_512(img)\n",
        "        tiles = split_image(img, n)\n",
        "\n",
        "        base = os.path.splitext(fname)[0]\n",
        "        for i, tile in enumerate(tiles, start=1):\n",
        "            outname = f\"{base}_{i:02d}.png\"\n",
        "            tile.save(os.path.join(output_folder, outname))\n",
        "\n",
        "    print(\"✓ PNG tiling complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pALCDf0juu0p",
        "outputId": "52e687b2-6e50-46a7-edd2-416ae37bb011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found: 479 TIFFs.\n",
            "First few: ['microscopy/LSDS-55_microscopy_1.1.tif', 'microscopy/LSDS-55_microscopy_1.1001.tif', 'microscopy/LSDS-55_microscopy_1.1002.tif', 'microscopy/LSDS-55_microscopy_1.1003.tif', 'microscopy/LSDS-55_microscopy_1.2.tif']\n",
            "Shape of parsed TIFF stack: (1, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# Preview PNG tiles instead of TIFF\n",
        "# ======================================\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "png_folder = Path(\"png_tiles\")   # <-- change to your output folder\n",
        "png_files = list(png_folder.glob(\"*.png\"))\n",
        "\n",
        "print(f\"Found {len(png_files)} PNG tiles.\")\n",
        "\n",
        "if png_files:\n",
        "    img = Image.open(png_files[0])\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(f\"Preview: {png_files[0].name}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "\n",
        "# if OUTPUT_ZIP.exists():\n",
        "#     with zipfile.ZipFile(OUTPUT_ZIP, \"r\") as zf:\n",
        "#         # Collect all TIFF-like members\n",
        "#         tif_files = [name for name in zf.namelist() if name.lower().endswith((\".tif\", \".tiff\"))]\n",
        "#         print(f\"Found {len(tif_files)} TIFFs in zip:\", tif_files[:5], \"...\" if len(tif_files) > 5 else \"\")\n",
        "\n",
        "#         # Example: read one TIFF file into a numpy array\n",
        "#         def read_tif_from_zip(zip_file, filename):\n",
        "#             with zip_file.open(filename) as f:\n",
        "#                 img_bytes = io.BytesIO(f.read())\n",
        "#                 return tiff.imread(img_bytes)\n",
        "\n",
        "#         # Example: preview shape of the first TIFF\n",
        "#         if len(tif_files) > 0:\n",
        "#             sample_img = read_tif_from_zip(zf, tif_files[0])\n",
        "#             print(\"Example image shape:\", sample_img.shape)\n",
        "\n",
        "# else:\n",
        "#     raise FileNotFoundError(f\"ZIP archive not found at {OUTPUT_ZIP!r}. Please update the path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "_lthqAQNzE8l",
        "outputId": "9bd47cfc-261a-45f6-8497-6f5b51ff3736"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>source_id</th>\n",
              "      <th>spaceflight</th>\n",
              "      <th>material</th>\n",
              "      <th>medium</th>\n",
              "      <th>time</th>\n",
              "      <th>microscopy_tif</th>\n",
              "      <th>microscopy_tif_alt_lower_g</th>\n",
              "      <th>microscopy_tif_alt_double_dot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [sample_id, source_id, spaceflight, material, medium, time, microscopy_tif, microscopy_tif_alt_lower_g, microscopy_tif_alt_double_dot]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed rows: 0\n",
            "Unique materials (first 10): []\n",
            "Unique media (first 10): []\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import re, unicodedata\n",
        "\n",
        "S_OSD_TXT = Path(\"s_OSD-627.txt\")\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    # keep words but drop punctuation so we can match phrases robustly\n",
        "    s = re.sub(r\"[\\[\\]\\(\\)\\{\\}:;,_\\-\\/\\\\]+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def _find_col(cols, *aliases):\n",
        "    \"\"\"\n",
        "    Return the first column whose normalized name contains ALL words\n",
        "    of any alias phrase provided.\n",
        "    \"\"\"\n",
        "    norm_map = {c: _norm(c) for c in cols}\n",
        "    for alias in aliases:\n",
        "        phrases = alias if isinstance(alias, (list, tuple)) else [alias]\n",
        "        for phrase in phrases:\n",
        "            phrase_norm = _norm(phrase)\n",
        "            words = phrase_norm.split()\n",
        "            for col, n in norm_map.items():\n",
        "                if all(w in n for w in words):\n",
        "                    return col\n",
        "    return None\n",
        "\n",
        "def parse_s_osd(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    # Core columns\n",
        "    col_sample = _find_col(\n",
        "        df.columns,\n",
        "        \"sample name\", \"sample id\"\n",
        "    )\n",
        "    col_source = _find_col(\n",
        "        df.columns,\n",
        "        \"source name\"\n",
        "    )\n",
        "    col_sf = _find_col(\n",
        "        df.columns,\n",
        "        # common ISA-tab encodings\n",
        "        \"factor value spaceflight\",\n",
        "        \"characteristics spaceflight\",\n",
        "        \"spaceflight\"\n",
        "    )\n",
        "    col_time = _find_col(\n",
        "        df.columns,\n",
        "        \"factor value time point\",\n",
        "        \"factor value time\",\n",
        "        \"time point\",\n",
        "        \"time\"\n",
        "    )\n",
        "\n",
        "    # Material shows up under many names; search broadly\n",
        "    col_material = _find_col(\n",
        "        df.columns,\n",
        "        \"factor value material\",\n",
        "        \"characteristics material\",\n",
        "        \"material\",\n",
        "        \"growth surface\",\n",
        "        \"factor value growth surface\",\n",
        "        \"characteristics growth surface\",\n",
        "        \"substrate\",\n",
        "        \"coupon material\",\n",
        "        \"alloy\",\n",
        "        \"stainless steel\"\n",
        "    )\n",
        "\n",
        "    # Medium often appears as Parameter Value[...] in ISA-tab\n",
        "    col_medium = _find_col(\n",
        "        df.columns,\n",
        "        \"parameter value sample media information\",\n",
        "        \"sample media information\",\n",
        "        \"factor value medium\",\n",
        "        \"characteristics medium\",\n",
        "        \"medium\",\n",
        "    )\n",
        "\n",
        "    # Hard requirements (don’t fail on Material/Medium)\n",
        "    required = {\n",
        "        \"Sample Name\": col_sample,\n",
        "        \"Source Name\": col_source,\n",
        "        \"Spaceflight\": col_sf,\n",
        "        \"Time\": col_time,\n",
        "    }\n",
        "    missing = [k for k, v in required.items() if v is None]\n",
        "    if missing:\n",
        "        raise ValueError(f\"s_OSD file is missing expected columns (none matched): {missing}\\n\"\n",
        "                         f\"Available columns:\\n{list(df.columns)}\")\n",
        "\n",
        "    # Build output\n",
        "    out = pd.DataFrame({\n",
        "        \"sample_id\": df[col_sample].str.strip(),\n",
        "        \"source_id\": df[col_source].str.strip(),\n",
        "        \"spaceflight\": df[col_sf].str.strip(),\n",
        "        \"time\": df[col_time].str.strip(),\n",
        "        # Optional fields with safe fallbacks\n",
        "        \"material\": (df[col_material].str.strip() if col_material else \"UnknownMaterial\"),\n",
        "        \"medium\": (df[col_medium].str.strip() if col_medium else \"UnknownMedium\"),\n",
        "    })\n",
        "\n",
        "    # Normalize numeric time\n",
        "    out[\"time\"] = pd.to_numeric(out[\"time\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # Fill blanks after strip\n",
        "    out[\"material\"] = out[\"material\"].fillna(\"UnknownMaterial\").replace(\"\", \"UnknownMaterial\")\n",
        "    out[\"medium\"]   = out[\"medium\"].fillna(\"UnknownMedium\").replace(\"\", \"UnknownMedium\")\n",
        "\n",
        "    # Generate TIFF candidate names that match your naming convention\n",
        "    out[\"microscopy_tif\"] = \"LSDS-55_microscopy_\" + out[\"sample_id\"] + \".tif\"\n",
        "    out[\"microscopy_tif_alt_lower_g\"] = \"LSDS-55_microscopy_\" + out[\"sample_id\"].str.replace(r\"^G\", \"g\", regex=True) + \".tif\"\n",
        "    out[\"microscopy_tif_alt_double_dot\"] = \"LSDS-55_microscopy_\" + out[\"sample_id\"].str.replace(r\"^([Gg]\\d+)\\.(\\d+)$\", r\"\\1..\\2\", regex=True) + \".tif\"\n",
        "\n",
        "    # Debug: show what we matched so you can confirm quickly\n",
        "    print(\"Matched columns →\",\n",
        "          dict(sample=col_sample, source=col_source, spaceflight=col_sf,\n",
        "               time=col_time, material=col_material, medium=col_medium))\n",
        "\n",
        "    return out[[\n",
        "        \"sample_id\",\"source_id\",\"spaceflight\",\"material\",\"medium\",\"time\",\n",
        "        \"microscopy_tif\",\"microscopy_tif_alt_lower_g\",\"microscopy_tif_alt_double_dot\"\n",
        "    ]]\n",
        "\n",
        "# Use the parser\n",
        "if S_OSD_TXT.exists():\n",
        "    s_osd_df = parse_s_osd(S_OSD_TXT)\n",
        "else:\n",
        "    s_osd_df = pd.DataFrame(columns=[\n",
        "        \"sample_id\",\"source_id\",\"spaceflight\",\"material\",\"medium\",\"time\",\n",
        "        \"microscopy_tif\",\"microscopy_tif_alt_lower_g\",\"microscopy_tif_alt_double_dot\"\n",
        "    ])\n",
        "\n",
        "display(s_osd_df.head(10))\n",
        "print(\"Parsed rows:\", len(s_osd_df))\n",
        "print(\"Unique materials (first 10):\", s_osd_df[\"material\"].unique()[:10])\n",
        "print(\"Unique media (first 10):\", s_osd_df[\"medium\"].unique()[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "4f8d522f",
        "outputId": "48489728-530a-487b-80ec-c454a54d0770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manifest preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tif_file\\tsample_id\\tsample_key\\tspaceflight\\ttime\\tmaterial_type\\tmedium\\trna_available\\trna_sample_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSDS-55_microscopy_1.1.tif\\t1.1\\t1.1\\tSpace Fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSDS-55_microscopy_1.1001.tif\\t1.1\\t1.1\\tSpace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LSDS-55_microscopy_1.1002.tif\\t1.1\\t1.1\\tSpace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LSDS-55_microscopy_1.1003.tif\\t1.1\\t1.1\\tSpace...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSDS-55_microscopy_1.2.tif\\t1.2\\t1.2\\tSpace Fl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  tif_file\\tsample_id\\tsample_key\\tspaceflight\\ttime\\tmaterial_type\\tmedium\\trna_available\\trna_sample_name\n",
              "0  LSDS-55_microscopy_1.1.tif\\t1.1\\t1.1\\tSpace Fl...                                                       \n",
              "1  LSDS-55_microscopy_1.1001.tif\\t1.1\\t1.1\\tSpace...                                                       \n",
              "2  LSDS-55_microscopy_1.1002.tif\\t1.1\\t1.1\\tSpace...                                                       \n",
              "3  LSDS-55_microscopy_1.1003.tif\\t1.1\\t1.1\\tSpace...                                                       \n",
              "4  LSDS-55_microscopy_1.2.tif\\t1.2\\t1.2\\tSpace Fl...                                                       "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provisional preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tif_file</th>\n",
              "      <th>sample_key</th>\n",
              "      <th>spaceflight</th>\n",
              "      <th>time</th>\n",
              "      <th>material_type</th>\n",
              "      <th>rna_available</th>\n",
              "      <th>rna_sample_name</th>\n",
              "      <th>tif_relpath</th>\n",
              "      <th>modality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSDS-55_microscopy_G1..1001.tif</td>\n",
              "      <td>G1.1</td>\n",
              "      <td>Ground</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cells</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LSDS-55_microscopy_G1..1001.tif</td>\n",
              "      <td>microscopy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSDS-55_microscopy_G1.1.tif</td>\n",
              "      <td>G1.1</td>\n",
              "      <td>Ground</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cells</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LSDS-55_microscopy_G1.1.tif</td>\n",
              "      <td>microscopy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LSDS-55_microscopy_G1.1002.tif</td>\n",
              "      <td>G1.1</td>\n",
              "      <td>Ground</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cells</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LSDS-55_microscopy_G1.1002.tif</td>\n",
              "      <td>microscopy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LSDS-55_microscopy_G1.1003.tif</td>\n",
              "      <td>G1.1</td>\n",
              "      <td>Ground</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cells</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LSDS-55_microscopy_G1.1003.tif</td>\n",
              "      <td>microscopy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSDS-55_microscopy_G1.2.tif</td>\n",
              "      <td>G1.2</td>\n",
              "      <td>Ground</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cells</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LSDS-55_microscopy_G1.2.tif</td>\n",
              "      <td>microscopy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          tif_file sample_key spaceflight  time material_type  \\\n",
              "0  LSDS-55_microscopy_G1..1001.tif       G1.1      Ground   1.0         Cells   \n",
              "1      LSDS-55_microscopy_G1.1.tif       G1.1      Ground   1.0         Cells   \n",
              "2   LSDS-55_microscopy_G1.1002.tif       G1.1      Ground   1.0         Cells   \n",
              "3   LSDS-55_microscopy_G1.1003.tif       G1.1      Ground   1.0         Cells   \n",
              "4      LSDS-55_microscopy_G1.2.tif       G1.2      Ground   1.0         Cells   \n",
              "\n",
              "   rna_available  rna_sample_name                      tif_relpath    modality  \n",
              "0          False              NaN  LSDS-55_microscopy_G1..1001.tif  microscopy  \n",
              "1          False              NaN      LSDS-55_microscopy_G1.1.tif  microscopy  \n",
              "2          False              NaN   LSDS-55_microscopy_G1.1002.tif  microscopy  \n",
              "3          False              NaN   LSDS-55_microscopy_G1.1003.tif  microscopy  \n",
              "4          False              NaN      LSDS-55_microscopy_G1.2.tif  microscopy  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'': []}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# --- Fallback linking via provided manifests ---\n",
        "# Map images (their filename suffix) to suggested RNA column names.\n",
        "manifest_df = pd.read_csv(MANIFEST_CSV) if MANIFEST_CSV.exists() else pd.DataFrame()\n",
        "provisional_df = pd.read_csv(PROVISIONAL_CSV) if PROVISIONAL_CSV.exists() else pd.DataFrame()\n",
        "\n",
        "print(\"Manifest preview:\")\n",
        "display(manifest_df.head(5) if not manifest_df.empty else \"No manifest found\")\n",
        "\n",
        "print(\"Provisional preview:\")\n",
        "display(provisional_df.head(5) if not provisional_df.empty else \"No provisional mapping found\")\n",
        "\n",
        "# Build an image->RNA columns mapping (list) using suggested_rna_cols\n",
        "image_to_rna_cols = {}\n",
        "if not provisional_df.empty:\n",
        "    for _,row in provisional_df.iterrows():\n",
        "        key = str(row.get(\"tif_suffix\",\"\")).strip()\n",
        "        cols = []\n",
        "        for c in [\"suggested_rna_cols\",\"suggested_rna_cols_2\",\"suggested_rna_cols_3\",\"suggested_rna_cols_4\"]:\n",
        "            val = row.get(c, None)\n",
        "            if isinstance(val, str) and val.strip():\n",
        "                cols.extend([s.strip() for s in val.split(\",\") if s.strip()])\n",
        "        image_to_rna_cols[key] = sorted(set(cols))\n",
        "\n",
        "image_to_rna_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emcLg0rbzE8l",
        "outputId": "4f92ff3c-068e-4c31-e717-2ce1aff2ac03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4f8fb92",
        "outputId": "18df1697-4043-4a78-cc40-f80069911d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNA sheet missing: Normalized_counts\\SSMicro_day1v3_bytime.xlsx\n",
            "RNA sheet missing: Normalized_counts\\SSGround_day1v3_bytime.xlsx\n",
            "RNA sheet missing: Normalized_counts\\SS_day3_bygravity.xlsx\n",
            "RNA sheet missing: Normalized_counts\\Micro_day3_bymaterial.xlsx\n",
            "RNA sheet missing: Normalized_counts\\LIS_day3_bygravity.xlsx\n",
            "RNA sheet missing: Normalized_counts\\Ground_day3_bymaterial.xlsx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Load RNA tables and standardize column keys ---\n",
        "def load_rna_tables(xlsx_paths):\n",
        "    tables = {}\n",
        "    for p in xlsx_paths:\n",
        "        if not Path(p).exists():\n",
        "            print(f\"RNA sheet missing: {p}\")\n",
        "            continue\n",
        "        try:\n",
        "            df = pd.read_excel(p)\n",
        "        except Exception:\n",
        "            # Some Excel files need engine specification depending on environment; try again\n",
        "            df = pd.read_excel(p, engine=\"openpyxl\")\n",
        "        # Normalize column names (strip spaces)\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "        tables[Path(p).stem] = df\n",
        "    return tables\n",
        "\n",
        "rna_tables = load_rna_tables(RNA_SHEETS)\n",
        "for name, df in rna_tables.items():\n",
        "    print(name, df.shape, \"cols:\", list(df.columns[:12]), \"...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "89AOLXHVzE8l"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def collect_available_rna_prefixes(rna_tables):\n",
        "    prefixes_by_sf = {'G': set(), 'F': set()}\n",
        "    cols_by_prefix = {}\n",
        "    pat = re.compile(r'^(?P<sf>[GF])(?P<prefix>\\d+)\\.(?P<rest>.+)$')\n",
        "    for _, df in (rna_tables or {}).items():\n",
        "        for c in df.columns:\n",
        "            m = pat.match(str(c))\n",
        "            if not m:\n",
        "                continue\n",
        "            sf = m.group('sf')\n",
        "            pfx = int(m.group('prefix'))\n",
        "            prefixes_by_sf[sf].add(pfx)\n",
        "            cols_by_prefix.setdefault((sf, pfx), set()).add(c)\n",
        "    return {k: sorted(v) for k,v in prefixes_by_sf.items()}, cols_by_prefix\n",
        "\n",
        "def parse_img_token(img_name):\n",
        "    m = re.search(r'([GF])(\\d+)\\.\\.?(\\d+)', img_name)\n",
        "    if not m: return None\n",
        "    sf = m.group(1); base_idx = int(m.group(2)); rest = m.group(3)\n",
        "    return sf, base_idx, rest\n",
        "\n",
        "def nearest_prefix(sf, want_prefix, prefixes_by_sf):\n",
        "    avail = prefixes_by_sf.get(sf, [])\n",
        "    if not avail: return None\n",
        "    return min(avail, key=lambda x: abs(x - want_prefix))\n",
        "\n",
        "def map_img_to_rna_cols(img_name, prefixes_by_sf, cols_by_prefix):\n",
        "    tok = parse_img_token(img_name)\n",
        "    if tok is None: return []\n",
        "    sf, base_idx, rest = tok\n",
        "    pfx = nearest_prefix(sf, base_idx, prefixes_by_sf)\n",
        "    if pfx is None: return []\n",
        "    cand = f\"{sf}{pfx}.{rest}\"\n",
        "    pool = cols_by_prefix.get((sf, pfx), set())\n",
        "    return [cand] if cand in pool else []\n",
        "\n",
        "prefixes_by_sf, cols_by_prefix = collect_available_rna_prefixes(rna_tables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c7bb7ba",
        "outputId": "f0497186-494d-43ef-a17a-2876c68e0af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning 479 TIFF-like entries in ZIP...\n",
            "Loaded 479 TIFFs into memory (keyed by basename).\n",
            "Sample shapes: {'LSDS-55_microscopy_1.1.tif': (1, 256, 256), 'LSDS-55_microscopy_1.1001.tif': (1, 256, 256), 'LSDS-55_microscopy_1.1002.tif': (1, 256, 256), 'LSDS-55_microscopy_1.1003.tif': (1, 256, 256), 'LSDS-55_microscopy_1.2.tif': (1, 256, 256)}\n"
          ]
        }
      ],
      "source": [
        "import io, zipfile\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configure your zip path (already set earlier) ---\n",
        "# DATA_ZIP_PATH = Path(\"microscopy_images.zip\")\n",
        "\n",
        "# --- Magic byte check for TIFF/BigTIFF ---\n",
        "def _is_tiff_magic(first4: bytes) -> bool:\n",
        "    # Classic TIFF:  b'II*\\x00' or b'MM\\x00*'\n",
        "    # BigTIFF:       b'II+\\x00' or b'MM\\x00+'\n",
        "    return first4 in (b'II*\\x00', b'MM\\x00*', b'II+\\x00', b'MM\\x00+')\n",
        "\n",
        "def read_tif_from_zip_validated(zf: zipfile.ZipFile, member: str) -> np.ndarray:\n",
        "    # Quick header check\n",
        "    with zf.open(member) as f:\n",
        "        head = f.read(4)\n",
        "        if not _is_tiff_magic(head):\n",
        "            raise ValueError(f\"Not a TIFF by magic: {member!r} header={head!r}\")\n",
        "        # Read full payload now\n",
        "        data = head + f.read()\n",
        "    # arr = tiff.imread(io.BytesIO(data))\n",
        "    arr = np.array(Image.open(io.BytesIO(data)))\n",
        "\n",
        "    # Ensure [T,H,W]\n",
        "    if arr.ndim == 2:\n",
        "        arr = arr[None, ...]\n",
        "    else:\n",
        "        arr = np.squeeze(arr)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, ...]\n",
        "        elif arr.ndim != 3:\n",
        "            raise ValueError(f\"Unexpected array ndim={arr.ndim} for {member}\")\n",
        "    return arr.astype(np.float32)\n",
        "\n",
        "# --- Build tif_map safely from ZIP ---\n",
        "tif_map = {}\n",
        "skipped = []\n",
        "\n",
        "if not OUTPUT_ZIP.exists():\n",
        "    raise FileNotFoundError(f\"ZIP archive not found: {OUTPUT_ZIP}\")\n",
        "\n",
        "with zipfile.ZipFile(OUTPUT_ZIP, \"r\") as zf:\n",
        "    candidates = [\n",
        "        name for name in zf.namelist()\n",
        "        if name.lower().endswith((\".tif\", \".tiff\"))\n",
        "        and not name.endswith(\"/\")\n",
        "        and not name.startswith(\"__MACOSX/\")\n",
        "    ]\n",
        "    print(f\"Scanning {len(candidates)} TIFF-like entries in ZIP...\")\n",
        "\n",
        "    for name in sorted(candidates):\n",
        "        try:\n",
        "            arr = read_tif_from_zip_validated(zf, name)  # or your read_tif_from_zip(...)\n",
        "            base = Path(name).name                        # <<<<<< KEY CHANGE: basename\n",
        "            tif_map[base] = arr\n",
        "        except Exception as e:\n",
        "            skipped.append((name, str(e)))\n",
        "\n",
        "print(f\"Loaded {len(tif_map)} TIFFs into memory (keyed by basename).\")\n",
        "if skipped:\n",
        "    print(f\"Skipped {len(skipped)} entries (not TIFF or unreadable); showing up to 10:\")\n",
        "    for n, msg in skipped[:10]:\n",
        "        print(\"  -\", n, \"->\", msg)\n",
        "\n",
        "# Optional: quick peek at shapes\n",
        "summary = {k: v.shape for k, v in list(tif_map.items())[:5]}\n",
        "print(\"Sample shapes:\", summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gDa8Yh7OzE8m"
      },
      "outputs": [],
      "source": [
        "def resolve_tif_name(row, available_names: set[str]):\n",
        "    \"\"\"\n",
        "    Given a row of s_osd_df and a set of available TIFF names (keys of tif_map),\n",
        "    return the first matching filename or None.\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "    for col in (\"microscopy_tif\", \"microscopy_tif_alt_lower_g\", \"microscopy_tif_alt_double_dot\"):\n",
        "        if col in row and pd.notna(row[col]) and str(row[col]).strip():\n",
        "            candidates.append(str(row[col]).strip())\n",
        "    for c in candidates:\n",
        "        if c in available_names:\n",
        "            return c\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c06f4cc4"
      },
      "outputs": [],
      "source": [
        "# --- Trajectory construction (fixed) ---\n",
        "def build_trajectories(s_osd_df, image_to_rna_cols, tif_map):\n",
        "    groups = {}\n",
        "    if not s_osd_df.empty:\n",
        "        for (sf, mat, med), sub in s_osd_df.groupby(['spaceflight','material','medium']):\n",
        "            sub2 = sub.sort_values('time')\n",
        "            key = (sf, mat, med)\n",
        "            times, samples, images, rna_cols = [], [], [], []\n",
        "            for _, r in sub2.iterrows():\n",
        "                times.append(int(r['time']))\n",
        "                samples.append(r['sample_id'])\n",
        "                img_name = r['microscopy_tif']\n",
        "                images.append(img_name)\n",
        "\n",
        "                cols = image_to_rna_cols.get(r['sample_id'], [])\n",
        "                if not cols:\n",
        "                    cols = map_img_to_rna_cols(img_name, prefixes_by_sf, cols_by_prefix)\n",
        "                rna_cols.append(cols)\n",
        "            groups[key] = dict(times=times, samples=samples, images=images, rna_cols=rna_cols)\n",
        "    else:\n",
        "        # Fallback: infer by numeric suffix present in available names\n",
        "        key = (\"UnknownSpaceflight\", \"UnknownMaterial\", \"UnknownMedium\")\n",
        "        entries = []\n",
        "        for tif_name in sorted(available):\n",
        "            m = re.search(r\"(\\d+\\.\\d+)\", tif_name)\n",
        "            t = None\n",
        "            if m:\n",
        "                try:\n",
        "                    t = int(m.group(1).split(\".\")[1])\n",
        "                except Exception:\n",
        "                    t = None\n",
        "            suffix = m.group(1) if m else None\n",
        "            entries.append((tif_name, t, suffix))\n",
        "        entries.sort(key=lambda x: (x[1] if x[1] is not None else 9999, x[0]))\n",
        "        times   = [e[1] for e in entries]\n",
        "        images  = [e[0] for e in entries]\n",
        "        samples = [e[2] for e in entries]  # suffix as a stand-in\n",
        "        rna_cols = [image_to_rna_cols.get(e[2], []) for e in entries]\n",
        "        groups[key] = dict(times=times, samples=samples, images=images, rna_cols=rna_cols)\n",
        "\n",
        "    return groups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWBh90mOzE8m",
        "outputId": "29d01469-23c5-4206-b3be-95b523d22969"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'available' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Patch 3: Rebuild and inspect trajectories ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m groups \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_osd_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_to_rna_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtif_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Debug: print a quick summary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(groups\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m5\u001b[39m]:\n",
            "Cell \u001b[1;32mIn[14], line 24\u001b[0m, in \u001b[0;36mbuild_trajectories\u001b[1;34m(s_osd_df, image_to_rna_cols, tif_map)\u001b[0m\n\u001b[0;32m     22\u001b[0m key \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknownSpaceflight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknownMaterial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknownMedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m entries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tif_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mavailable\u001b[49m):\n\u001b[0;32m     25\u001b[0m     m \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\"\u001b[39m, tif_name)\n\u001b[0;32m     26\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'available' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Patch 3: Rebuild and inspect trajectories ---\n",
        "groups = build_trajectories(s_osd_df, image_to_rna_cols, tif_map)\n",
        "\n",
        "# Debug: print a quick summary\n",
        "for k, b in list(groups.items())[:5]:\n",
        "    n_valid = sum(1 for x in b['images'] if x)\n",
        "    print(f\"{k}: times={len(b['times'])}, resolvable_images={n_valid}/{len(b['images'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R4faOEVlzE8m"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple, Dict\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def _infer_day_from_table_name(name: str) -> Optional[int]:\n",
        "    low = name.lower()\n",
        "    if \"day1\" in low:\n",
        "        return 1\n",
        "    if \"day3\" in low:\n",
        "        return 3\n",
        "    return None\n",
        "\n",
        "def _candidate_rna_columns(df: pd.DataFrame) -> list:\n",
        "    # Keep only columns that look like RNA sample columns such as G4.1, F16.2, etc.\n",
        "    keep_pref = (\"G4.\", \"F4.\", \"G10.\", \"F10.\", \"G16.\", \"F16.\", \"G17.\", \"F17.\")\n",
        "    return [c for c in df.columns if any(c.startswith(p) for p in keep_pref)]\n",
        "\n",
        "def _prefix_of(col: str) -> Optional[str]:\n",
        "    # \"G4.1\" -> \"G4\", \"F16.7\" -> \"F16\"\n",
        "    m = re.match(r\"^([GF]\\d+)\\.\\d+$\", col)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def build_rna_group_features(\n",
        "    rna_tables: Dict[str, pd.DataFrame],\n",
        "    use_pca: bool = True,\n",
        "    pca_dim: int = 16\n",
        ") -> Tuple[Dict[Tuple[str, str, str, int], np.ndarray], dict]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      rna_group_vecs: dict keyed by (spaceflight, material, medium, day) -> np.ndarray (fixed length)\n",
        "      feature_meta:   dict with keys:\n",
        "                      - 'cols': list of aligned feature columns (before PCA)\n",
        "                      - 'pca':  fitted PCA object or None\n",
        "                      - 'rna_dim': final dimension after PCA (or original width if PCA not used)\n",
        "                      - 'map': helper mapping (rna_prefix -> row index in aligned matrix)\n",
        "    Notes:\n",
        "      * Because we don't have an exact mapping from (sf,mat,med,day) to RNA prefix (e.g., G4/F16),\n",
        "        we first build vectors per RNA *prefix* (G4, F16, ...). Later, when attaching to images/groups,\n",
        "        we’ll drop a zero vector if no compatible prefix is found.\n",
        "    \"\"\"\n",
        "    # 1) Collect all RNA-like columns across all tables\n",
        "    table_keep = {name: _candidate_rna_columns(df) for name, df in rna_tables.items()}\n",
        "    all_cols = sorted({c for cols in table_keep.values() for c in cols})\n",
        "    if not all_cols:\n",
        "        # No RNA-style columns anywhere -> return empty/zero config\n",
        "        return {}, {'cols': [], 'pca': None, 'rna_dim': 0, 'map': {}}\n",
        "\n",
        "    # 2) Aggregate per-table column means for stability\n",
        "    per_table_means = {}\n",
        "    for name, df in rna_tables.items():\n",
        "        cols = table_keep.get(name, [])\n",
        "        if not cols:\n",
        "            continue\n",
        "        means = {}\n",
        "        for c in cols:\n",
        "            s = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "            means[c] = float(np.nanmean(s.to_numpy())) if s.notna().any() else 0.0\n",
        "        per_table_means[name] = means\n",
        "\n",
        "    # 3) Build per-RNA-prefix Series (index = all_cols, values = means, fill missing with 0)\n",
        "    #    Example prefixes: G4, F4, G10, F10, G16, F16, G17, F17\n",
        "    prefix_set = sorted({_prefix_of(c) for c in all_cols if _prefix_of(c) is not None})\n",
        "    if not prefix_set:\n",
        "        return {}, {'cols': [], 'pca': None, 'rna_dim': 0, 'map': {}}\n",
        "\n",
        "    rows = []\n",
        "    row_keys = []   # each row key will be the RNA-prefix (e.g., \"G4\")\n",
        "    for pref in prefix_set:\n",
        "        # Merge from all tables (some cols might exist in >1 table; average them)\n",
        "        vals = {}\n",
        "        for col in all_cols:\n",
        "            if _prefix_of(col) == pref:\n",
        "                # collect from all tables that have this column\n",
        "                have = [per_table_means[t][col] for t in per_table_means if col in per_table_means[t]]\n",
        "                vals[col] = float(np.mean(have)) if len(have) > 0 else 0.0\n",
        "            else:\n",
        "                vals[col] = 0.0\n",
        "        rows.append(pd.Series(vals, index=all_cols, dtype=float))\n",
        "        row_keys.append(pref)\n",
        "\n",
        "    aligned = pd.DataFrame(rows, index=row_keys, columns=all_cols).fillna(0.0)  # [num_prefixes, num_features]\n",
        "\n",
        "    # 4) Optional PCA to fixed dim (safe guards)\n",
        "    fitted_pca = None\n",
        "    X = aligned.to_numpy(dtype=np.float32)\n",
        "    # If all-zero rows, PCA will complain; keep only rows with some variance to fit\n",
        "    fit_mask = (np.abs(X).sum(axis=1) > 0)\n",
        "    X_fit = X[fit_mask]\n",
        "    final_dim = X.shape[1]\n",
        "    if use_pca and X_fit.shape[0] >= 2 and X_fit.shape[1] > 1:\n",
        "        n_comp = min(pca_dim, X_fit.shape[1], X_fit.shape[0])  # cannot exceed #rows or #features\n",
        "        if n_comp >= 2:\n",
        "            fitted_pca = PCA(n_components=n_comp, svd_solver='auto', random_state=0)\n",
        "            fitted_pca.fit(X_fit)\n",
        "            X = fitted_pca.transform(X)\n",
        "            final_dim = X.shape[1]\n",
        "        else:\n",
        "            # too few samples to PCA meaningfully; skip\n",
        "            fitted_pca = None\n",
        "            final_dim = X.shape[1]\n",
        "    else:\n",
        "        fitted_pca = None\n",
        "        final_dim = X.shape[1]\n",
        "\n",
        "    # 5) Package: we do not yet know (sf, mat, med, day) mapping here, so we return prefix vectors only.\n",
        "    #    Callers will choose a prefix (e.g., based on sample-id like 'G4.*') or fall back to zeros.\n",
        "    rna_group_vecs = {}  # we’ll fill at attach time; keeping empty here is fine\n",
        "    feature_meta = {\n",
        "        'cols': all_cols,\n",
        "        'pca': fitted_pca,\n",
        "        'rna_dim': int(final_dim),\n",
        "        'map': {pref: X[i] for i, pref in enumerate(row_keys)}\n",
        "    }\n",
        "    return rna_group_vecs, feature_meta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_35-DSRzE8m",
        "outputId": "66840106-eb97-4269-e609-8b8deef6d562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNA feature meta: {'cols': ['F10.1', 'F10.2', 'F10.3', 'F10.4', 'F10.5', 'F10.6', 'F10.8', 'F16.1', 'F16.2', 'F16.3', 'F16.4', 'F16.5', 'F16.6', 'F16.7', 'F17.1', 'F17.2', 'F17.3', 'F17.4', 'F4.1', 'F4.2', 'F4.3', 'F4.4', 'F4.6', 'F4.7', 'F4.8', 'G10.1', 'G10.2', 'G10.3', 'G10.4', 'G10.5', 'G10.6', 'G10.8', 'G16.1', 'G16.2', 'G16.3', 'G16.4', 'G16.5', 'G16.6', 'G16.7', 'G17.1', 'G17.2', 'G17.3', 'G17.4', 'G4.1', 'G4.2', 'G4.3', 'G4.4', 'G4.6', 'G4.7', 'G4.8'], 'pca': PCA(n_components=8, random_state=0), 'rna_dim': 8, 'map': {'F10': array([-1.1397461e+03, -2.7714600e+03,  2.5533074e+03,  7.7301483e+02,\n",
            "        8.2930435e+01,  2.1947708e+01,  4.6491943e+01, -3.3378601e-05],\n",
            "      dtype=float32), 'F16': array([-6.6841602e+02, -3.9546271e+02, -2.4458098e+03,  2.2803062e+03,\n",
            "        1.3993834e+02,  3.5055450e+01,  6.7505676e+01,  1.2874603e-04],\n",
            "      dtype=float32), 'F17': array([-3.37156677e+02, -1.30221024e+02, -4.32754852e+02, -6.27714844e+02,\n",
            "       -2.20994293e+02, -8.36751175e+01, -9.14051025e+02,  1.04904175e-04],\n",
            "      dtype=float32), 'F4': array([-4.2974054e+02, -1.8381633e+02, -6.7386182e+02, -1.4086475e+03,\n",
            "        1.8228335e+03,  1.7714478e+02,  1.7178333e+02, -3.3092499e-04],\n",
            "      dtype=float32), 'G10': array([ 4.8080537e+03,  2.9049866e+02,  5.5679089e+02,  3.5793848e+02,\n",
            "        4.8364944e+01,  1.3253807e+01,  3.0070374e+01, -2.9277802e-04],\n",
            "      dtype=float32), 'G16': array([-3.9124432e+02, -1.6019243e+02, -5.6172327e+02, -9.7431952e+02,\n",
            "       -7.8780377e+02, -1.5155481e+03,  2.9909399e+02,  2.3746490e-04],\n",
            "      dtype=float32), 'G17': array([-3.9924557e+02, -1.6493475e+02, -5.8344470e+02, -1.0465065e+03,\n",
            "       -1.1592303e+03,  1.3320714e+03,  2.5655627e+02,  2.3746490e-04],\n",
            "      dtype=float32), 'G4': array([-1.4425046e+03,  3.5155884e+03,  1.5874962e+03,  6.4592902e+02,\n",
            "        7.3961380e+01,  1.9750130e+01,  4.2549500e+01, -2.7656555e-05],\n",
            "      dtype=float32)}}\n"
          ]
        }
      ],
      "source": [
        "rna_group_vecs, rna_feature_meta = build_rna_group_features(rna_tables, pca_dim=16, use_pca=True)\n",
        "GLOBAL_RNA_DIM = rna_feature_meta.get('rna_dim', 0)\n",
        "RNA_PREFIX_TO_VEC = rna_feature_meta.get('map', {})  # e.g., {'G4': np.array([...]), 'F16': ...}\n",
        "print(\"RNA feature meta:\", rna_feature_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VYp-nsCezE8m"
      },
      "outputs": [],
      "source": [
        "def _guess_rna_prefix(sample_or_img: str) -> Optional[str]:\n",
        "    # Look for patterns like 'G4.' or 'F16.' in the name; return 'G4' or 'F16'\n",
        "    m = re.search(r\"([GF]\\d+)\\.(?:\\d+)\", sample_or_img)\n",
        "    return m.group(1) if m else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4afa46",
        "outputId": "289a7ace-bdc6-4a11-c8dc-55c44e9ecee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample TIFF keys: ['LSDS-55_microscopy_1.1.tif', 'LSDS-55_microscopy_1.1001.tif', 'LSDS-55_microscopy_1.1002.tif', 'LSDS-55_microscopy_1.1003.tif', 'LSDS-55_microscopy_1.2.tif']\n",
            "Dataset samples: 467\n",
            "Sample[0] shapes: torch.Size([1, 1, 512, 512]) torch.Size([1, 1, 512, 512])\n",
            "X shape: (1, 1, 512, 512)\n",
            "Y shape: (1, 1, 512, 512)\n",
            "Aux RNA shape: (8,)\n",
            "Meta: {'key': ('Ground', 'Cells', 'LB broth (Lennox) supplemented with KNO3'), 't_in': 1, 't_out': 1, 'img_in': 'LSDS-55_microscopy_G1.1002.tif', 'img_out': 'LSDS-55_microscopy_G1.1003.tif'}\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "RESIZE_HW = (512, 512)\n",
        "# --- Dataset with optional RNA auxiliary features ---\n",
        "class TrajectoryDataset(Dataset):\n",
        "    def __init__(self, groups, tif_map, use_rna=True, resize_hw=RESIZE_HW):\n",
        "        self.samples = []\n",
        "        self.use_rna = use_rna and (GLOBAL_RNA_DIM > 0)\n",
        "        self.resize_hw = resize_hw\n",
        "\n",
        "        for key, bundle in groups.items():\n",
        "            times = bundle['times']\n",
        "            images = bundle['images']\n",
        "\n",
        "            for i in range(len(times)-1):\n",
        "                img_in_name = images[i]\n",
        "                img_out_name = images[i+1]\n",
        "                if img_in_name not in tif_map or img_out_name not in tif_map:\n",
        "                    continue\n",
        "\n",
        "                X_seq = tif_map[img_in_name]   # [T,H,W] or [1,H,W]\n",
        "                Y_seq = tif_map[img_out_name]  # [T,H,W] or [1,H,W]\n",
        "\n",
        "                # --- NEW: fixed-length RNA vector (or zeros) ---\n",
        "                if self.use_rna and GLOBAL_RNA_DIM > 0:\n",
        "                    pref_in  = _guess_rna_prefix(img_in_name)\n",
        "                    pref_out = _guess_rna_prefix(img_out_name)\n",
        "                    # use the input prefix if available; fallback to output; else zeros\n",
        "                    vec = None\n",
        "                    if pref_in in RNA_PREFIX_TO_VEC:\n",
        "                        vec = RNA_PREFIX_TO_VEC[pref_in]\n",
        "                    elif pref_out in RNA_PREFIX_TO_VEC:\n",
        "                        vec = RNA_PREFIX_TO_VEC[pref_out]\n",
        "                    if vec is None:\n",
        "                        vec = np.zeros((GLOBAL_RNA_DIM,), dtype=np.float32)\n",
        "                    rna_vec = vec.astype(np.float32)\n",
        "                else:\n",
        "                    rna_vec = None  # will be converted to zeros later to avoid collate errors\n",
        "\n",
        "                self.samples.append({\n",
        "                    \"X_seq\": X_seq,\n",
        "                    \"Y_seq\": Y_seq,\n",
        "                    \"rna_seq\": rna_vec,\n",
        "                    \"meta\": dict(key=key, t_in=times[i], t_out=times[i+1],\n",
        "                                 img_in=img_in_name, img_out=img_out_name)\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.samples[idx]\n",
        "        # X_seq, Y_seq are [T,H,W] numpy arrays\n",
        "        X = item[\"X_seq\"][None, ...]  # [1,T,H,W] treat T as channels\n",
        "        Y = item[\"Y_seq\"][None, ...]  # [1,T,H,W]\n",
        "        X = torch.from_numpy(X).float()\n",
        "        Y = torch.from_numpy(Y).float()\n",
        "\n",
        "        # --- normalize spatial sizes ---\n",
        "        if self.resize_hw is not None:\n",
        "            if X.shape[-2:] != self.resize_hw:\n",
        "                X = F.interpolate(X, size=self.resize_hw, mode=\"area\")\n",
        "            if Y.shape[-2:] != self.resize_hw:\n",
        "                Y = F.interpolate(Y, size=self.resize_hw, mode=\"area\")\n",
        "\n",
        "        # RNA vector (as you implemented) -> aux tensor or zeros\n",
        "        if self.use_rna and GLOBAL_RNA_DIM > 0:\n",
        "            if item[\"rna_seq\"] is None:\n",
        "                aux = torch.zeros((GLOBAL_RNA_DIM,), dtype=torch.float32)\n",
        "            else:\n",
        "                aux = torch.from_numpy(item[\"rna_seq\"]).float()\n",
        "        else:\n",
        "            aux = None\n",
        "\n",
        "        return X, Y, aux, item[\"meta\"]\n",
        "\n",
        "print(\"Sample TIFF keys:\", list(tif_map.keys())[:5])\n",
        "dataset = TrajectoryDataset(groups, tif_map, use_rna=True)\n",
        "print(\"Dataset samples:\", len(dataset))\n",
        "if len(dataset) > 0:\n",
        "    X, Y, aux, meta = dataset[0]\n",
        "    print(\"Sample[0] shapes:\", X.shape, Y.shape)\n",
        "if len(dataset):\n",
        "    X, Y, aux, meta = dataset[0]\n",
        "    print(\"X shape:\", (tuple(X.shape) if hasattr(X, 'shape') else type(X)))\n",
        "    print(\"Y shape:\", (tuple(Y.shape) if hasattr(Y, 'shape') else type(Y)))\n",
        "    print(\"Aux RNA shape:\", (tuple(aux.shape) if aux is not None else None))\n",
        "    print(\"Meta:\", meta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3100c5af",
        "outputId": "0c647494-c508-44f9-f90d-dd401b649a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNA dim: 8\n",
            "SmallPredictor(\n",
            "  (l1): ConvLSTMLayer(\n",
            "    (cell): ConvLSTMCell(\n",
            "      (conv): Conv2d(41, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (bn1): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (l2): ConvLSTMLayer(\n",
            "    (cell): ConvLSTMCell(\n",
            "      (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (bn2): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (l3): ConvLSTMLayer(\n",
            "    (cell): ConvLSTMCell(\n",
            "      (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (bn3): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (l4): ConvLSTMLayer(\n",
            "    (cell): ConvLSTMCell(\n",
            "      (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (bn4): BatchNorm3d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (head): Conv3d(40, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            "  (rna_mlp): Sequential(\n",
            "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Simple ConvNet baseline with optional RNA head (replace with ConvLSTM as needed) ---\n",
        "if 'torch' in globals():\n",
        "    class ConvLSTMCell(nn.Module):\n",
        "        def __init__(self, in_channels, hidden_channels, kernel_size=3, padding=1):\n",
        "            super().__init__()\n",
        "            self.hidden_channels = hidden_channels\n",
        "            self.conv = nn.Conv2d(in_channels + hidden_channels,\n",
        "                                4 * hidden_channels,\n",
        "                                kernel_size=kernel_size,\n",
        "                                padding=padding)\n",
        "\n",
        "        def forward(self, x_t, state):\n",
        "            # x_t: [B, C, H, W]; state: (h, c) each [B, hidden, H, W]\n",
        "            h_prev, c_prev = state\n",
        "            gates = self.conv(torch.cat([x_t, h_prev], dim=1))\n",
        "            i, f, o, g = torch.chunk(gates, 4, dim=1)\n",
        "            i = torch.sigmoid(i); f = torch.sigmoid(f); o = torch.sigmoid(o); g = torch.tanh(g)\n",
        "            c = f * c_prev + i * g\n",
        "            h = o * torch.tanh(c)\n",
        "            return h, c\n",
        "\n",
        "        def init_state(self, B, H, W, device=None, dtype=None):\n",
        "            h = torch.zeros(B, self.hidden_channels, H, W, device=device, dtype=dtype)\n",
        "            c = torch.zeros(B, self.hidden_channels, H, W, device=device, dtype=dtype)\n",
        "            return h, c\n",
        "\n",
        "    class ConvLSTMLayer(nn.Module):\n",
        "        \"\"\"\n",
        "        Full-sequence ConvLSTM.\n",
        "        Input : [B, T, C, H, W]\n",
        "        Output: [B, T, hidden, H, W]\n",
        "        \"\"\"\n",
        "        def __init__(self, in_channels, hidden_channels, kernel_size=3, padding=1):\n",
        "            super().__init__()\n",
        "            self.cell = ConvLSTMCell(in_channels, hidden_channels, kernel_size, padding)\n",
        "\n",
        "        def forward(self, x):\n",
        "            B, T, C, H, W = x.shape\n",
        "            device, dtype = x.device, x.dtype\n",
        "            h, c = self.cell.init_state(B, H, W, device, dtype)\n",
        "            outs = []\n",
        "            for t in range(T):\n",
        "                h, c = self.cell(x[:, t], (h, c))\n",
        "                outs.append(h)\n",
        "            return torch.stack(outs, dim=1)  # [B, T, hidden, H, W]\n",
        "\n",
        "\n",
        "# ===== ConvLSTM SmallPredictor (Keras-equivalent) =====\n",
        "    class SmallPredictor(nn.Module):\n",
        "        \"\"\"\n",
        "        Matches:\n",
        "        [ConvLSTM x4 (40 ch, return_sequences), BN between] -> Conv3D(1, k=(1,3,3)) -> sigmoid\n",
        "        Input : [B, 1, T, H, W]\n",
        "        Output: [B, 1, T, H, W]\n",
        "        \"\"\"\n",
        "        def __init__(self, use_rna=False, rna_dim=0):\n",
        "            super().__init__()\n",
        "            self.use_rna = use_rna and (rna_dim > 0)\n",
        "\n",
        "            self.l1 = ConvLSTMLayer(1, 40, 3, 1)\n",
        "            self.bn1 = nn.BatchNorm3d(40)\n",
        "            self.l2 = ConvLSTMLayer(40, 40, 3, 1)\n",
        "            self.bn2 = nn.BatchNorm3d(40)\n",
        "            self.l3 = ConvLSTMLayer(40, 40, 3, 1)\n",
        "            self.bn3 = nn.BatchNorm3d(40)\n",
        "            self.l4 = ConvLSTMLayer(40, 40, 3, 1)\n",
        "            self.bn4 = nn.BatchNorm3d(40)\n",
        "\n",
        "            # temporal kernel = 1 preserves T\n",
        "            self.head = nn.Conv3d(40, 1, kernel_size=(1, 3, 3), padding=(0, 1, 1))\n",
        "\n",
        "            if self.use_rna:\n",
        "                self.rna_mlp = nn.Sequential(\n",
        "                    nn.Linear(rna_dim, 16),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(16, 1)  # scalar per-batch\n",
        "                )\n",
        "\n",
        "        @staticmethod\n",
        "        def _bn3d(bn, y_btchw):\n",
        "            y_bcthw = y_btchw.permute(0, 2, 1, 3, 4)  # [B,C,T,H,W]\n",
        "            y_bcthw = bn(y_bcthw)\n",
        "            return y_bcthw.permute(0, 2, 1, 3, 4)     # [B,T,C,H,W]\n",
        "\n",
        "        def forward(self, x, rna=None):\n",
        "            # x: [B, 1, T, H, W] -> [B, T, 1, H, W]\n",
        "            B, C, T, H, W = x.shape\n",
        "            y = x.permute(0, 2, 1, 3, 4)\n",
        "\n",
        "            y = self._bn3d(self.bn1, self.l1(y))\n",
        "            y = self._bn3d(self.bn2, self.l2(y))\n",
        "            y = self._bn3d(self.bn3, self.l3(y))\n",
        "            y = self._bn3d(self.bn4, self.l4(y))\n",
        "\n",
        "            # head expects [B,C,T,H,W]\n",
        "            y = y.permute(0, 2, 1, 3, 4)  # [B,40,T,H,W]\n",
        "\n",
        "            if self.use_rna and (rna is not None):\n",
        "                bias = self.rna_mlp(rna).view(B, 1, 1, 1, 1)\n",
        "                y = y + bias\n",
        "\n",
        "            y = self.head(y)           # [B,1,T,H,W]\n",
        "            y = torch.sigmoid(y)\n",
        "            return y\n",
        "\n",
        "    # Probe RNA dim from dataset (first non-null)\n",
        "    rna_dim = 0\n",
        "    for i in range(len(dataset)):\n",
        "        _,_,aux,_ = dataset[i]\n",
        "        if aux is not None:\n",
        "            rna_dim = aux.shape[-1]\n",
        "            break\n",
        "    print(\"RNA dim:\", rna_dim)\n",
        "\n",
        "    model = SmallPredictor(use_rna=(rna_dim>0), rna_dim=rna_dim)\n",
        "    print(model)\n",
        "\n",
        "else:\n",
        "    print(\"Torch not available; skip model construction.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "C_jky6QezE8m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def robust_norm01(t: torch.Tensor, q_low=0.01, q_high=0.99, eps=1e-6):\n",
        "    # t: [B,1,H,W] float\n",
        "    # compute robust min/max per-sample using quantiles\n",
        "    q1 = torch.quantile(t.flatten(2), q_low, dim=2, keepdim=True)\n",
        "    q9 = torch.quantile(t.flatten(2), q_high, dim=2, keepdim=True)\n",
        "    span = (q9 - q1).clamp_min(eps)\n",
        "    t_flat = (t.flatten(2) - q1).clamp_min(0) / span\n",
        "    t = t_flat.view_as(t).clamp(0, 1)\n",
        "    return t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id_3ycmYzE8n",
        "outputId": "fa0cbc2f-b2b1-49e3-9fc6-a9ba84c8dbed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4143704320.py:39: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipython-input-4143704320.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 00000 | loss 0.48366 | X (1, 1, 1, 512, 512)\n",
            "step 00010 | loss 0.35357 | X (1, 1, 1, 512, 512)\n",
            "step 00020 | loss 0.29567 | X (1, 1, 1, 512, 512)\n",
            "step 00030 | loss 0.25087 | X (1, 1, 1, 512, 512)\n",
            "step 00040 | loss 0.20535 | X (1, 1, 1, 512, 512)\n",
            "step 00050 | loss 0.20392 | X (1, 1, 1, 512, 512)\n",
            "step 00060 | loss 0.20267 | X (1, 1, 1, 512, 512)\n",
            "step 00070 | loss 0.17091 | X (1, 1, 1, 512, 512)\n",
            "step 00080 | loss 0.19620 | X (1, 1, 1, 512, 512)\n",
            "step 00090 | loss 0.22131 | X (1, 1, 1, 512, 512)\n",
            "step 00100 | loss 0.15991 | X (1, 1, 1, 512, 512)\n",
            "step 00110 | loss 0.25544 | X (1, 1, 1, 512, 512)\n",
            "step 00120 | loss 0.19646 | X (1, 1, 1, 512, 512)\n",
            "step 00130 | loss 0.13182 | X (1, 1, 1, 512, 512)\n",
            "step 00140 | loss 0.22160 | X (1, 1, 1, 512, 512)\n",
            "step 00150 | loss 0.24231 | X (1, 1, 1, 512, 512)\n",
            "step 00160 | loss 0.22744 | X (1, 1, 1, 512, 512)\n",
            "step 00170 | loss 0.15848 | X (1, 1, 1, 512, 512)\n",
            "step 00180 | loss 0.15031 | X (1, 1, 1, 512, 512)\n",
            "step 00190 | loss 0.16474 | X (1, 1, 1, 512, 512)\n",
            "step 00200 | loss 0.13334 | X (1, 1, 1, 512, 512)\n",
            "step 00210 | loss 0.30088 | X (1, 1, 1, 512, 512)\n",
            "step 00220 | loss 0.21525 | X (1, 1, 1, 512, 512)\n",
            "step 00230 | loss 0.23564 | X (1, 1, 1, 512, 512)\n",
            "step 00240 | loss 0.14065 | X (1, 1, 1, 512, 512)\n",
            "step 00250 | loss 0.20758 | X (1, 1, 1, 512, 512)\n",
            "step 00260 | loss 0.14432 | X (1, 1, 1, 512, 512)\n",
            "step 00270 | loss 0.15642 | X (1, 1, 1, 512, 512)\n",
            "step 00280 | loss 0.14604 | X (1, 1, 1, 512, 512)\n",
            "step 00290 | loss 0.11715 | X (1, 1, 1, 512, 512)\n",
            "step 00300 | loss 0.10364 | X (1, 1, 1, 512, 512)\n",
            "step 00310 | loss 0.15386 | X (1, 1, 1, 512, 512)\n",
            "step 00320 | loss 0.21131 | X (1, 1, 1, 512, 512)\n",
            "step 00330 | loss 0.15083 | X (1, 1, 1, 512, 512)\n",
            "step 00340 | loss 0.12457 | X (1, 1, 1, 512, 512)\n",
            "step 00350 | loss 0.07826 | X (1, 1, 1, 512, 512)\n",
            "step 00360 | loss 0.06542 | X (1, 1, 1, 512, 512)\n",
            "step 00370 | loss 0.09093 | X (1, 1, 1, 512, 512)\n",
            "step 00380 | loss 0.15606 | X (1, 1, 1, 512, 512)\n",
            "step 00390 | loss 0.09851 | X (1, 1, 1, 512, 512)\n",
            "step 00400 | loss 0.19282 | X (1, 1, 1, 512, 512)\n",
            "step 00410 | loss 0.17623 | X (1, 1, 1, 512, 512)\n",
            "step 00420 | loss 0.25682 | X (1, 1, 1, 512, 512)\n",
            "step 00430 | loss 0.23262 | X (1, 1, 1, 512, 512)\n",
            "step 00440 | loss 0.10370 | X (1, 1, 1, 512, 512)\n",
            "step 00450 | loss 0.08441 | X (1, 1, 1, 512, 512)\n",
            "step 00460 | loss 0.08338 | X (1, 1, 1, 512, 512)\n"
          ]
        }
      ],
      "source": [
        "# --- Memory-safe ConvLSTM training loop (drop-in replacement) ---\n",
        "if 'torch' in globals() and len(dataset) > 0:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.utils.data import DataLoader\n",
        "    from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "    # --------- knobs you can tweak without touching the core loop ----------\n",
        "    BATCH_SIZE = 1                 # bump if you can\n",
        "    NUM_WORKERS = 2                # >0 speeds CPU->GPU input\n",
        "    PIN_MEMORY = True              # good for CUDA\n",
        "    T_SUB = 1                      # e.g., 2 = use every 2nd frame (cuts memory ~1/2)\n",
        "    CROP_HW = None                 # e.g., (256,256) to crop HxW from top-left\n",
        "    MAX_GRAD_NORM = 1.0\n",
        "    LR = 3e-4\n",
        "    WD = 1e-5\n",
        "    HUBER_BETA = 0.01\n",
        "\n",
        "    # cudnn autotune can help perf; safe for fixed-size inputs\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "    loss_fn = nn.SmoothL1Loss(beta=HUBER_BETA)\n",
        "\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    # ---------- helpers ----------\n",
        "    def robust_norm_seq(x):\n",
        "        # x: [B, C, T, H, W]; returns [B, C, T, H, W] in [0,1]\n",
        "        B, C, T, H, W = x.shape\n",
        "        xf = x.reshape(B, C, T * H * W)\n",
        "        q1 = torch.quantile(xf, 0.01, dim=2, keepdim=True)\n",
        "        q9 = torch.quantile(xf, 0.99, dim=2, keepdim=True)\n",
        "        span = (q9 - q1).clamp_min(1e-6)\n",
        "        xf = ((xf - q1).clamp_min(0) / span).clamp(0, 1)\n",
        "        return xf.view(B, C, T, H, W)\n",
        "\n",
        "    def maybe_subsample_time(z, step=T_SUB):\n",
        "        # z: [B, C, T, H, W]\n",
        "        if step is None or step <= 1:\n",
        "            return z\n",
        "        return z[:, :, ::step]\n",
        "\n",
        "    def maybe_crop_hw(z, crop=CROP_HW):\n",
        "        # z: [B, C, T, H, W]\n",
        "        if not crop:\n",
        "            return z\n",
        "        Hc, Wc = crop\n",
        "        return z[..., :Hc, :Wc]\n",
        "\n",
        "    # ---------- train ----------\n",
        "    model.train()\n",
        "    for step, (X, Y, aux, meta) in enumerate(loader):\n",
        "        # Shapes to device\n",
        "        X = X.to(device, dtype=torch.float32, non_blocking=True)  # [B,1,T,H,W]\n",
        "        Y = Y.to(device, dtype=torch.float32, non_blocking=True)  # [B,1,T,H,W]\n",
        "\n",
        "        # Optional temporal subsampling & cropping (reduces memory a lot)\n",
        "        if T_SUB and T_SUB > 1:\n",
        "            X = maybe_subsample_time(X, T_SUB)\n",
        "            Y = maybe_subsample_time(Y, T_SUB)\n",
        "        if CROP_HW:\n",
        "            X = maybe_crop_hw(X, CROP_HW)\n",
        "            Y = maybe_crop_hw(Y, CROP_HW)\n",
        "\n",
        "        # RNA aux handling\n",
        "        if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "            aux_dim = model.rna_mlp[0].in_features\n",
        "        else:\n",
        "            aux_dim = 0\n",
        "        if aux_dim > 0:\n",
        "            aux = aux.to(device, dtype=torch.float32, non_blocking=True) if (aux is not None) \\\n",
        "                  else torch.zeros((X.shape[0], aux_dim), device=device)\n",
        "        else:\n",
        "            aux = None\n",
        "\n",
        "        # Normalization OUTSIDE autograd to avoid huge graphs\n",
        "        with torch.no_grad():\n",
        "            Xn = robust_norm_seq(X)\n",
        "            Yn = robust_norm_seq(Y)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward + loss in AMP (on GPU) to halve activation memory\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            pred = model(Xn, rna=aux)  # [B,1,T,H,W]\n",
        "\n",
        "            # If a spatial mismatch slipped in, align Yn to pred\n",
        "            if Yn.shape[-2:] != pred.shape[-2:]:\n",
        "                B, C, T, H, W = Yn.shape\n",
        "                Yn_4d = Yn.permute(0, 2, 1, 3, 4).reshape(B * T, C, H, W)  # [B*T,1,H,W]\n",
        "                Yn_4d = F.interpolate(Yn_4d, size=pred.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "                Hp, Wp = pred.shape[-2:]\n",
        "                Yn = Yn_4d.reshape(B, T, C, Hp, Wp).permute(0, 2, 1, 3, 4)\n",
        "\n",
        "            loss = loss_fn(pred, Yn)\n",
        "\n",
        "        # Backward (scaled) + clip + step\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(opt)\n",
        "        clip_grad_norm_(model.parameters(), max_norm=MAX_GRAD_NORM)\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        # (Optional) lightweight logging\n",
        "        if (step % 10) == 0:\n",
        "            print(f\"step {step:05d} | loss {loss.item():.5f} | X {tuple(X.shape)}\")\n",
        "\n",
        "        # Emergency break if something grows without bound (rare)\n",
        "        if not torch.isfinite(loss):\n",
        "            print(\"Non-finite loss detected; breaking to protect the run.\")\n",
        "            break\n",
        "\n",
        "else:\n",
        "    print(\"Skipping training (no torch or no samples).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRyp92NCpPEO",
        "outputId": "7988a78d-50f7-4249-e94d-6ce753fa9900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to convlstm_bacteria_growth.pt\n"
          ]
        }
      ],
      "source": [
        "# --- Save trained model ---\n",
        "MODEL_SAVE_PATH = \"convlstm_bacteria_growth.pt\"\n",
        "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "print(f\"Model saved to {MODEL_SAVE_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "x0iqmS3WzE8n"
      },
      "outputs": [],
      "source": [
        "# --- meta normalization helpers ---\n",
        "def _unwrap_meta(meta_batch):\n",
        "    \"\"\"\n",
        "    Make a single-sample meta dict from what DataLoader collates.\n",
        "    Handles:\n",
        "      - list/tuple of dicts\n",
        "      - dict of lists\n",
        "      - plain dict\n",
        "    \"\"\"\n",
        "    if isinstance(meta_batch, (list, tuple)) and len(meta_batch) > 0:\n",
        "        return meta_batch[0]\n",
        "    if isinstance(meta_batch, dict):\n",
        "        # dict of lists? take the first element from each list\n",
        "        any_val = next(iter(meta_batch.values())) if len(meta_batch) else None\n",
        "        if isinstance(any_val, (list, tuple)) and len(any_val) > 0:\n",
        "            return {k: v[0] for k, v in meta_batch.items()}\n",
        "        return meta_batch\n",
        "    return {\"key\": \"UNK\"}\n",
        "\n",
        "def _normalize_group_key(g):\n",
        "    \"\"\"\n",
        "    Convert group key into a hashable thing for dicts:\n",
        "      - list -> tuple\n",
        "      - other iterables -> tuple\n",
        "      - None -> \"UNK\"\n",
        "    \"\"\"\n",
        "    if g is None:\n",
        "        return \"UNK\"\n",
        "    if isinstance(g, (list, tuple)):\n",
        "        return tuple(g)\n",
        "    # strings are fine\n",
        "    if isinstance(g, str):\n",
        "        return g\n",
        "    # anything iterable (e.g., numpy array)\n",
        "    try:\n",
        "        return tuple(g)\n",
        "    except Exception:\n",
        "        return str(g)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HjkY0QWsdif",
        "outputId": "3b2b6b2c-870c-46c9-88a5-4fdf02e3ab3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2426680653.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[eval] 0 samples in 5.3s\n",
            "[eval] 10 samples in 22.0s\n",
            "[eval] 20 samples in 35.6s\n",
            "[eval] 30 samples in 47.8s\n",
            "[eval] 40 samples in 60.1s\n",
            "== Fast eval ==\n",
            "MAE  : 0.0825\n",
            "MSE  : 0.0141\n",
            "PSNR : 20.7919\n"
          ]
        }
      ],
      "source": [
        "import math, time, torch, torch.nn.functional as F\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ---- knobs to control eval cost ----\n",
        "EVAL_MAX_BATCHES = 50      # e.g., 50 to cap runtime\n",
        "EVAL_T_SUB = 1               # e.g., 2 -> every 2nd frame\n",
        "EVAL_CROP_HW = (256,256)          # e.g., (256,256)\n",
        "EVAL_COMPUTE_SSIM = False    # turn off to speed up a lot\n",
        "EVAL_DOWNSAMPLE_FOR_METRICS = 2  # e.g., 2 -> metrics on half-res (cheap)\n",
        "EVAL_NUM_WORKERS = 2\n",
        "EVAL_PIN_MEMORY  = True\n",
        "\n",
        "def _to_float01(x: torch.Tensor) -> torch.Tensor:\n",
        "    return x.clamp(0.0, 1.0)\n",
        "\n",
        "def mae(pred, tgt):\n",
        "    pred = _to_float01(pred); tgt = _to_float01(tgt)\n",
        "    return torch.mean(torch.abs(pred - tgt)).item()\n",
        "\n",
        "def mse(pred, tgt):\n",
        "    pred = _to_float01(pred); tgt = _to_float01(tgt)\n",
        "    return torch.mean((pred - tgt) ** 2).item()\n",
        "\n",
        "def psnr(pred, tgt, data_range=1.0):\n",
        "    m = mse(pred, tgt)\n",
        "    if m <= 1e-12:\n",
        "        return float(\"inf\")\n",
        "    return 20.0 * math.log10(data_range) - 10.0 * math.log10(m)\n",
        "\n",
        "# fast Gaussian kernel for SSIM (only used if EVAL_COMPUTE_SSIM=True)\n",
        "def _gaussian_kernel(size=11, sigma=1.5, device=\"cpu\", dtype=torch.float32):\n",
        "    coords = torch.arange(size, device=device, dtype=dtype) - size // 2\n",
        "    g = torch.exp(-(coords**2)/(2*sigma**2))\n",
        "    g = g / g.sum()\n",
        "    k2 = (g[:, None] @ g[None, :])\n",
        "    return (k2 / k2.sum())\n",
        "\n",
        "def ssim(pred, tgt, data_range=1.0, size=11, sigma=1.5):\n",
        "    k = _gaussian_kernel(size=size, sigma=sigma, device=pred.device, dtype=pred.dtype)[None, None, :, :]\n",
        "    C1 = (0.01 * data_range) ** 2\n",
        "    C2 = (0.03 * data_range) ** 2\n",
        "    def filt(x): return F.conv2d(x, k, padding=size//2, groups=1)\n",
        "    mu_x, mu_y = filt(pred), filt(tgt)\n",
        "    mu_x2, mu_y2, mu_xy = mu_x*mu_x, mu_y*mu_y, mu_x*mu_y\n",
        "    sigma_x2 = filt(pred*pred) - mu_x2\n",
        "    sigma_y2 = filt(tgt*tgt) - mu_y2\n",
        "    sigma_xy = filt(pred*tgt) - mu_xy\n",
        "    ssim_map = ((2*mu_xy + C1) * (2*sigma_xy + C2)) / ((mu_x2 + mu_y2 + C1) * (sigma_x2 + sigma_y2 + C2))\n",
        "    return ssim_map.mean().item()\n",
        "\n",
        "# fast min/max normalization (no quantiles)\n",
        "def fast_norm_seq(x):\n",
        "    # x: [B, C, T, H, W]\n",
        "    B, C, T, H, W = x.shape\n",
        "    # x_flat = x.view(B, C, -1)            # ❌ causes error if x is non-contiguous\n",
        "    x_flat = x.reshape(B, C, -1)           # ✅ handles non-contiguous tensors\n",
        "    lo = torch.amin(x_flat, dim=2, keepdim=True)\n",
        "    hi = torch.amax(x_flat, dim=2, keepdim=True)\n",
        "    span = (hi - lo).clamp_min(1e-6)\n",
        "    x_norm = ((x_flat - lo) / span).clamp(0, 1)\n",
        "    # return x_norm.view(B, C, T, H, W)    # ❌\n",
        "    return x_norm.reshape(B, C, T, H, W)   # ✅\n",
        "\n",
        "def maybe_subsample_time(z, step):\n",
        "    return z if (step is None or step <= 1) else z[:, :, ::step]\n",
        "\n",
        "def maybe_crop_hw(z, crop):\n",
        "    if not crop: return z\n",
        "    Hc, Wc = crop\n",
        "    return z[..., :Hc, :Wc]\n",
        "\n",
        "def maybe_downsample_for_metrics(x4, factor):\n",
        "    # x4: [B,1,H,W]\n",
        "    if factor is None or factor <= 1: return x4\n",
        "    return F.interpolate(x4, scale_factor=1.0/factor, mode=\"area\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model_fast(model, dataset, device, reduce_over_time=\"mean\"):\n",
        "    loader = DataLoader(\n",
        "        dataset, batch_size=1, shuffle=False,\n",
        "        num_workers=EVAL_NUM_WORKERS, pin_memory=EVAL_PIN_MEMORY\n",
        "    )\n",
        "    model.eval()\n",
        "    use_amp = (device.type == \"cuda\")\n",
        "\n",
        "    agg = dict(mae=[], mse=[], psnr=[])\n",
        "    if EVAL_COMPUTE_SSIM:\n",
        "        agg[\"ssim\"] = []\n",
        "\n",
        "    t0 = time.time()\n",
        "    for step, (X, Y, aux, meta) in enumerate(loader):\n",
        "        X = X.to(device, dtype=torch.float32, non_blocking=True)  # [B,1,T,H,W]\n",
        "        Y = Y.to(device, dtype=torch.float32, non_blocking=True)\n",
        "\n",
        "        # throttle cost\n",
        "        if EVAL_T_SUB and EVAL_T_SUB > 1:\n",
        "            X = maybe_subsample_time(X, EVAL_T_SUB)\n",
        "            Y = maybe_subsample_time(Y, EVAL_T_SUB)\n",
        "        if EVAL_CROP_HW:\n",
        "            X = maybe_crop_hw(X, EVAL_CROP_HW)\n",
        "            Y = maybe_crop_hw(Y, EVAL_CROP_HW)\n",
        "\n",
        "        # fast normalization\n",
        "        Xn = fast_norm_seq(X)\n",
        "        Yn = fast_norm_seq(Y)\n",
        "\n",
        "        # aux\n",
        "        if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "            k = model.rna_mlp[0].in_features\n",
        "            aux = (aux.to(device, dtype=torch.float32, non_blocking=True)\n",
        "                   if (aux is not None) else torch.zeros((X.shape[0], k), device=device))\n",
        "        else:\n",
        "            aux = None\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            pred_seq = model(Xn, rna=aux)  # [B,1,T,H,W]\n",
        "\n",
        "        # reduce to 2D\n",
        "        if reduce_over_time == \"mean\":\n",
        "            pred2d = pred_seq.mean(dim=2)\n",
        "            Y2d    = Yn.mean(dim=2)\n",
        "        else:  # 'last'\n",
        "            pred2d = pred_seq[:, :, -1]\n",
        "            Y2d    = Yn[:, :, -1]\n",
        "\n",
        "        # downsample for metric speed, if requested\n",
        "        if EVAL_DOWNSAMPLE_FOR_METRICS and EVAL_DOWNSAMPLE_FOR_METRICS > 1:\n",
        "            pred2d_m = maybe_downsample_for_metrics(pred2d, EVAL_DOWNSAMPLE_FOR_METRICS)\n",
        "            Y2d_m    = maybe_downsample_for_metrics(Y2d,    EVAL_DOWNSAMPLE_FOR_METRICS)\n",
        "        else:\n",
        "            pred2d_m, Y2d_m = pred2d, Y2d\n",
        "\n",
        "        # metrics\n",
        "        agg[\"mae\"].append(mae(pred2d_m, Y2d_m))\n",
        "        agg[\"mse\"].append(mse(pred2d_m, Y2d_m))\n",
        "        agg[\"psnr\"].append(psnr(pred2d_m, Y2d_m, data_range=1.0))\n",
        "        if EVAL_COMPUTE_SSIM:\n",
        "            agg[\"ssim\"].append(ssim(pred2d_m, Y2d_m, data_range=1.0))\n",
        "\n",
        "        if (step % 10) == 0:\n",
        "            dt = time.time() - t0\n",
        "            print(f\"[eval] {step} samples in {dt:.1f}s\")\n",
        "\n",
        "        if (EVAL_MAX_BATCHES is not None) and (step + 1 >= EVAL_MAX_BATCHES):\n",
        "            break\n",
        "\n",
        "    # summarize\n",
        "    out = {k: (float(np.mean(v)) if len(v)>0 else float(\"nan\")) for k,v in agg.items()}\n",
        "    return out\n",
        "\n",
        "# ---- run fast eval ----\n",
        "if 'torch' in globals() and len(dataset) > 0:\n",
        "    device_eval = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device_eval)\n",
        "    summary = evaluate_model_fast(model, dataset, device_eval, reduce_over_time=\"mean\")\n",
        "    print(\"== Fast eval ==\")\n",
        "    for k,v in summary.items():\n",
        "        print(f\"{k.upper():5s}: {v:.4f}\")\n",
        "else:\n",
        "    print(\"Skip eval: no torch or empty dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "XZDn6w4vzE8n",
        "outputId": "05483943-35a7-490a-cacf-b6a975514e98"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2392734388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mdevice_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_over_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"== Global metrics ==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2392734388.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, loader, device, max_batches, reduce_over_time)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mm_mse\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mm_psnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mm_ssim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2392734388.py\u001b[0m in \u001b[0;36mssim\u001b[0;34m(pred, tgt, data_range, size, sigma)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0msigma_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0msigma_y2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_y2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0msigma_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_xy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mssim_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmu_xy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma_xy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_x2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu_y2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma_x2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma_y2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2392734388.py\u001b[0m in \u001b[0;36mfilt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# import math, torch, torch.nn.functional as F\n",
        "# import numpy as np\n",
        "# from collections import defaultdict\n",
        "\n",
        "# # --- helpers ---\n",
        "# def _to_float01(x: torch.Tensor) -> torch.Tensor:\n",
        "#     \"\"\"Clamp to [0,1]; assumes your pipeline already scales to [0,1].\"\"\"\n",
        "#     return x.clamp(0.0, 1.0)\n",
        "\n",
        "# def mae(pred, tgt):\n",
        "#     pred = _to_float01(pred); tgt = _to_float01(tgt)\n",
        "#     return torch.mean(torch.abs(pred - tgt)).item()\n",
        "\n",
        "# def mse(pred, tgt):\n",
        "#     pred = _to_float01(pred); tgt = _to_float01(tgt)\n",
        "#     return torch.mean((pred - tgt) ** 2).item()\n",
        "\n",
        "# def psnr(pred, tgt, data_range=1.0):\n",
        "#     m = mse(pred, tgt)\n",
        "#     if m <= 1e-12:\n",
        "#         return float(\"inf\")\n",
        "#     return 20.0 * math.log10(data_range) - 10.0 * math.log10(m)\n",
        "\n",
        "# # --- SSIM (PyTorch) ---\n",
        "# def _gaussian_kernel(size=11, sigma=1.5, device=\"cpu\", dtype=torch.float32):\n",
        "#     coords = torch.arange(size, device=device, dtype=dtype) - size // 2\n",
        "#     g = torch.exp(-(coords**2)/(2*sigma**2))\n",
        "#     g = g / g.sum()\n",
        "#     k2 = (g[:, None] @ g[None, :])\n",
        "#     return (k2 / k2.sum())\n",
        "\n",
        "# def ssim(pred, tgt, data_range=1.0, size=11, sigma=1.5):\n",
        "#     \"\"\"\n",
        "#     pred/tgt: [B,1,H,W] tensors in [0,1]\n",
        "#     Returns mean SSIM over batch.\n",
        "#     \"\"\"\n",
        "#     device, dtype = pred.device, pred.dtype\n",
        "#     pred = _to_float01(pred); tgt = _to_float01(tgt)\n",
        "\n",
        "#     C1 = (0.01 * data_range) ** 2\n",
        "#     C2 = (0.03 * data_range) ** 2\n",
        "\n",
        "#     k = _gaussian_kernel(size=size, sigma=sigma, device=device, dtype=dtype)[None, None, :, :]\n",
        "#     def filt(x): return F.conv2d(x, k, padding=size//2, groups=1)\n",
        "\n",
        "#     mu_x, mu_y = filt(pred), filt(tgt)\n",
        "#     mu_x2, mu_y2, mu_xy = mu_x*mu_x, mu_y*mu_y, mu_x*mu_y\n",
        "\n",
        "#     sigma_x2 = filt(pred*pred) - mu_x2\n",
        "#     sigma_y2 = filt(tgt*tgt) - mu_y2\n",
        "#     sigma_xy = filt(pred*tgt) - mu_xy\n",
        "\n",
        "#     ssim_map = ((2*mu_xy + C1) * (2*sigma_xy + C2)) / ((mu_x2 + mu_y2 + C1) * (sigma_x2 + sigma_y2 + C2))\n",
        "#     return ssim_map.mean().item()\n",
        "\n",
        "# # --- safe meta helpers (no-ops if you already have your own) ---\n",
        "# def _unwrap_meta(meta):\n",
        "#     # meta may be a list/tuple of dicts when coming from DataLoader\n",
        "#     if isinstance(meta, (list, tuple)) and len(meta) > 0:\n",
        "#         meta = meta[0]\n",
        "#     return meta if isinstance(meta, dict) else {}\n",
        "\n",
        "# def _normalize_group_key(k):\n",
        "#     # Expect a tuple like (spaceflight, material, medium), else make a string key\n",
        "#     if isinstance(k, (tuple, list)):\n",
        "#         return tuple(k)\n",
        "#     return str(k)\n",
        "\n",
        "# # --- normalization like training ---\n",
        "# def robust_norm_seq(x):\n",
        "#     # x: [B, C, T, H, W] -> [B, C, T, H, W] in [0,1]\n",
        "#     B, C, T, H, W = x.shape\n",
        "#     xf = x.reshape(B, C, T * H * W)\n",
        "#     q1 = torch.quantile(xf, 0.01, dim=2, keepdim=True)\n",
        "#     q9 = torch.quantile(xf, 0.99, dim=2, keepdim=True)\n",
        "#     span = (q9 - q1).clamp_min(1e-6)\n",
        "#     xf = ((xf - q1).clamp_min(0) / span).clamp(0, 1)\n",
        "#     return xf.view(B, C, T, H, W)\n",
        "\n",
        "# # --- evaluation loop ---\n",
        "# @torch.no_grad()\n",
        "# def evaluate_model(model, loader, device, max_batches=None, reduce_over_time=\"mean\"):\n",
        "#     \"\"\"\n",
        "#     reduce_over_time: 'mean' (default) or 'last' or None (for per-frame aggregation)\n",
        "#     \"\"\"\n",
        "#     model.eval()\n",
        "#     agg = dict(mae=[], mse=[], psnr=[], ssim=[])\n",
        "#     per_group = defaultdict(lambda: dict(mae=[], mse=[], psnr=[], ssim=[]))\n",
        "\n",
        "#     seen = 0\n",
        "#     for step, (X, Y, aux, meta) in enumerate(loader):\n",
        "#         # Move to device\n",
        "#         X = X.to(device=device, dtype=torch.float32)  # [B,1,T,H,W]\n",
        "#         Y = Y.to(device=device, dtype=torch.float32)  # [B,1,T,H,W]\n",
        "\n",
        "#         # Normalize like training (no_grad)\n",
        "#         with torch.no_grad():\n",
        "#             Xn = robust_norm_seq(X)\n",
        "#             Yn = robust_norm_seq(Y)\n",
        "\n",
        "#         # Prepare aux if the model expects it\n",
        "#         if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "#             aux_dim = model.rna_mlp[0].in_features\n",
        "#             aux = (aux.to(device, dtype=torch.float32) if (aux is not None) else\n",
        "#                    torch.zeros((X.shape[0], aux_dim), device=device))\n",
        "#         else:\n",
        "#             aux = None\n",
        "\n",
        "#         # Forward\n",
        "#         pred_seq = model(Xn, rna=aux)           # [B,1,T,H,W]\n",
        "\n",
        "#         # Reduce to 2D for metrics\n",
        "#         if reduce_over_time == \"mean\":\n",
        "#             pred2d = pred_seq.mean(dim=2)       # [B,1,H,W]\n",
        "#             Y2d    = Yn.mean(dim=2)             # [B,1,H,W]\n",
        "#         elif reduce_over_time == \"last\":\n",
        "#             pred2d = pred_seq[:, :, -1]         # [B,1,H,W]\n",
        "#             Y2d    = Yn[:, :, -1]\n",
        "#         else:\n",
        "#             # Per-frame metrics aggregated over T (uncomment to use)\n",
        "#             # B, C, T, H, W = pred_seq.shape\n",
        "#             # p4 = pred_seq.permute(0,2,1,3,4).reshape(B*T, C, H, W)\n",
        "#             # y4 = Yn.permute(0,2,1,3,4).reshape(B*T, C, H, W)\n",
        "#             # m_mae  = mae(p4, y4); m_mse = mse(p4, y4)\n",
        "#             # m_psnr = psnr(p4, y4, data_range=1.0); m_ssim = ssim(p4, y4, data_range=1.0)\n",
        "#             # (then append and continue)\n",
        "#             raise NotImplementedError(\"Set reduce_over_time to 'mean' or 'last' for 2D metrics.\")\n",
        "\n",
        "#         # Metrics (2D)\n",
        "#         m_mae  = mae(pred2d, Y2d)\n",
        "#         m_mse  = mse(pred2d, Y2d)\n",
        "#         m_psnr = psnr(pred2d, Y2d, data_range=1.0)\n",
        "#         m_ssim = ssim(pred2d, Y2d, data_range=1.0)\n",
        "\n",
        "#         agg[\"mae\"].append(m_mae)\n",
        "#         agg[\"mse\"].append(m_mse)\n",
        "#         agg[\"psnr\"].append(m_psnr)\n",
        "#         agg[\"ssim\"].append(m_ssim)\n",
        "\n",
        "#         meta0 = _unwrap_meta(meta)\n",
        "#         group_key = _normalize_group_key(meta0.get(\"key\", \"UNK\"))\n",
        "#         per_group[group_key][\"mae\"].append(m_mae)\n",
        "#         per_group[group_key][\"mse\"].append(m_mse)\n",
        "#         per_group[group_key][\"psnr\"].append(m_psnr)\n",
        "#         per_group[group_key][\"ssim\"].append(m_ssim)\n",
        "\n",
        "#         seen += 1\n",
        "#         if (max_batches is not None) and (seen >= max_batches):\n",
        "#             break\n",
        "\n",
        "#     def _summ(d):\n",
        "#         return {k: (float(np.mean(v)) if len(v) > 0 else float(\"nan\")) for k, v in d.items()}\n",
        "\n",
        "#     summary = _summ(agg)\n",
        "#     per_group_summary = {g: _summ(mdict) for g, mdict in per_group.items()}\n",
        "#     return summary, per_group_summary\n",
        "\n",
        "# # --- Run eval ---\n",
        "# if 'torch' in globals() and len(dataset) > 0:\n",
        "#     from torch.utils.data import DataLoader\n",
        "#     eval_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "#     device_eval = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model = model.to(device_eval)\n",
        "#     summary, per_group = evaluate_model(model, eval_loader, device_eval, max_batches=200, reduce_over_time=\"mean\")\n",
        "#     print(\"== Global metrics ==\")\n",
        "#     for k, v in summary.items():\n",
        "#         print(f\"{k.upper():5s}: {v:.4f}\")\n",
        "#     print(\"\\n== Per-group (first 8) ==\")\n",
        "#     for i, (g, s) in enumerate(per_group.items()):\n",
        "#         if i >= 8: break\n",
        "#         gstr = \" | \".join(map(str, g)) if isinstance(g, (tuple, list)) else str(g)\n",
        "#         print(f\"{gstr}\\n  \" + \"  \".join([f\"{k}:{s[k]:.4f}\" for k in (\"mae\",\"mse\",\"psnr\",\"ssim\")]))\n",
        "# else:\n",
        "#     print(\"Skip eval: no torch or empty dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "WvtIMsXazE8n"
      },
      "outputs": [],
      "source": [
        "# # ===== Visualization Utilities =====\n",
        "# import numpy as np\n",
        "# from pathlib import Path\n",
        "# import tifffile as tiff\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def _to_np_uint8(x01):\n",
        "#     x = (np.clip(x01, 0, 1) * 255.0).round().astype(np.uint8)\n",
        "#     return x\n",
        "\n",
        "# def save_timelapse_tiff(input_seq, pred_seq, target_seq, out_path: Path):\n",
        "#     \"\"\"\n",
        "#     input_seq, pred_seq, target_seq: numpy arrays in [T, H, W] scaled to [0,1]\n",
        "#     Writes a multi-page TIFF where each page is an H x (3W) panel: [input | pred | target].\n",
        "#     \"\"\"\n",
        "#     out_path = Path(out_path)\n",
        "#     out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#     T, H, W = input_seq.shape\n",
        "#     pages = []\n",
        "#     for t in range(T):\n",
        "#         panel = np.concatenate([\n",
        "#             _to_np_uint8(input_seq[t]),\n",
        "#             _to_np_uint8(pred_seq[t]),\n",
        "#             _to_np_uint8(target_seq[t])\n",
        "#         ], axis=1)  # H x (3W)\n",
        "#         pages.append(panel)\n",
        "\n",
        "#     with tiff.TiffWriter(str(out_path), bigtiff=True) as tw:\n",
        "#         for p in pages:\n",
        "#             tw.write(p, photometric='minisblack')\n",
        "\n",
        "# def plot_growth_curve(input_seq, pred_seq, target_seq, out_png: Path, title=\"Bacterial growth proxy\"):\n",
        "#     \"\"\"\n",
        "#     Simple growth proxy = sum of normalized intensities per frame.\n",
        "#     \"\"\"\n",
        "#     out_png = Path(out_png)\n",
        "#     out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#     g_in  = input_seq.reshape(input_seq.shape[0], -1).sum(axis=1)\n",
        "#     g_pr  = pred_seq.reshape(pred_seq.shape[0], -1).sum(axis=1)\n",
        "#     g_tar = target_seq.reshape(target_seq.shape[0], -1).sum(axis=1)\n",
        "\n",
        "#     plt.figure(figsize=(6,4))\n",
        "#     plt.plot(g_in, label=\"input\")\n",
        "#     plt.plot(g_pr, label=\"prediction\")\n",
        "#     plt.plot(g_tar, label=\"target\")\n",
        "#     plt.xlabel(\"frame (t)\")\n",
        "#     plt.ylabel(\"sum of intensities\")\n",
        "#     plt.title(title)\n",
        "#     plt.legend()\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(out_png, dpi=150)\n",
        "#     plt.close()\n",
        "\n",
        "# def make_viz_for_sample(model, dataset, idx=0, device=\"cpu\", out_dir=\"viz\"):\n",
        "#     \"\"\"\n",
        "#     Runs a single dataset sample through the model and writes:\n",
        "#       - timelapse panels: viz/sample_{idx}.tif\n",
        "#       - growth curve:     viz/sample_{idx}_growth.png\n",
        "#     \"\"\"\n",
        "#     model.eval()\n",
        "#     X, Y, aux, meta = dataset[idx]   # X/Y: [1,T,H,W] torch\n",
        "#     with torch.no_grad():\n",
        "#         X = X.unsqueeze(0).to(device)        # [1,1,T,H,W]\n",
        "#         Y = Y.unsqueeze(0).to(device)        # [1,1,T,H,W]\n",
        "#         # normalize like training (frame-wise)\n",
        "#         def _robust_norm_seq_torch(z):\n",
        "#             B,C,T,H,W = z.shape\n",
        "#             zf = z.view(B,C,-1)\n",
        "#             q1 = torch.quantile(zf, 0.01, dim=2, keepdim=True)\n",
        "#             q9 = torch.quantile(zf, 0.99, dim=2, keepdim=True)\n",
        "#             span = (q9 - q1).clamp_min(1e-6)\n",
        "#             zf = ((zf - q1).clamp_min(0) / span).clamp(0,1)\n",
        "#             return zf.view(B,C,T,H,W)\n",
        "#         Xn = _robust_norm_seq_torch(X)\n",
        "#         Yn = _robust_norm_seq_torch(Y)\n",
        "\n",
        "#         # RNA zeros if needed\n",
        "#         if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "#             aux_dim = model.rna_mlp[0].in_features\n",
        "#             aux = torch.zeros((1, aux_dim), device=device)\n",
        "#         else:\n",
        "#             aux = None\n",
        "\n",
        "#         Pred = model(Xn, rna=aux)  # [1,1,T,H,W]\n",
        "\n",
        "#     # to numpy [T,H,W] in [0,1]\n",
        "#     x_np = Xn.squeeze(0).squeeze(0).cpu().numpy()\n",
        "#     y_np = Yn.squeeze(0).squeeze(0).cpu().numpy()\n",
        "#     p_np = Pred.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "#     out_dir = Path(out_dir)\n",
        "#     out_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     tiff_path = out_dir / f\"sample_{idx}.tif\"\n",
        "#     png_path  = out_dir / f\"sample_{idx}_growth.png\"\n",
        "\n",
        "#     save_timelapse_tiff(x_np, p_np, y_np, tiff_path)\n",
        "#     plot_growth_curve(x_np, p_np, y_np, png_path, title=f\"Growth (sample {idx})\")\n",
        "\n",
        "#     print(f\"[viz] wrote {tiff_path} and {png_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "USVOqRFw-gRN"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     import imageio.v2 as imageio\n",
        "#     def write_gif_from_tiff(tiff_path, gif_path):\n",
        "#         stack = tiff.imread(str(tiff_path))  # [T, H, 3W] uint8\n",
        "#         imageio.mimsave(gif_path, [frame for frame in stack], duration=0.2)\n",
        "#         print(f\"[viz] wrote {gif_path}\")\n",
        "#     write_gif_from_tiff(tiff_path, tiff_path.with_suffix(\".gif\"))\n",
        "# except Exception as _e:\n",
        "#     pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcNtoAYiu-dv"
      },
      "outputs": [],
      "source": [
        "# ===== Visualization Utilities =====\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def _to_np_uint8(x01: np.ndarray) -> np.ndarray:\n",
        "    x = (np.clip(x01, 0, 1) * 255.0).round().astype(np.uint8)\n",
        "    return x\n",
        "\n",
        "def save_timelapse_tiff(input_seq, pred_seq, target_seq, out_path: Path):\n",
        "    \"\"\"\n",
        "    input_seq, pred_seq, target_seq: numpy arrays in [T, H, W] scaled to [0,1]\n",
        "    Writes a multi-page TIFF where each page is an H x (3W) panel: [input | pred | target].\n",
        "    \"\"\"\n",
        "    out_path = Path(out_path)\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    T, H, W = input_seq.shape\n",
        "    with tiff.TiffWriter(str(out_path), bigtiff=True) as tw:\n",
        "        for t_idx in range(T):\n",
        "            panel = np.concatenate([\n",
        "                _to_np_uint8(input_seq[t_idx]),\n",
        "                _to_np_uint8(pred_seq[t_idx]),\n",
        "                _to_np_uint8(target_seq[t_idx]),\n",
        "            ], axis=1)  # H x (3W)\n",
        "            tw.write(panel, photometric='minisblack')\n",
        "\n",
        "def plot_growth_curve(input_seq, pred_seq, target_seq, out_png: Path, title=\"Bacterial growth proxy\"):\n",
        "    \"\"\"\n",
        "    Simple growth proxy = sum of normalized intensities per frame.\n",
        "    \"\"\"\n",
        "    out_png = Path(out_png)\n",
        "    out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    g_in  = input_seq.reshape(input_seq.shape[0], -1).sum(axis=1)\n",
        "    g_pr  = pred_seq.reshape(pred_seq.shape[0], -1).sum(axis=1)\n",
        "    g_tar = target_seq.reshape(target_seq.shape[0], -1).sum(axis=1)\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(g_in,  label=\"input\")\n",
        "    plt.plot(g_pr,  label=\"prediction\")\n",
        "    plt.plot(g_tar, label=\"target\")\n",
        "    plt.xlabel(\"frame (t)\")\n",
        "    plt.ylabel(\"sum of intensities\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_png, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "def _fast_norm_seq_torch(z: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Min/max normalization to [0,1] per-sample across T*H*W. Safer & faster than quantiles.\"\"\"\n",
        "    B,C,T,H,W = z.shape\n",
        "    zf = z.reshape(B, C, -1)\n",
        "    lo = torch.amin(zf, dim=2, keepdim=True)\n",
        "    hi = torch.amax(zf, dim=2, keepdim=True)\n",
        "    span = (hi - lo).clamp_min(1e-6)\n",
        "    zf = ((zf - lo) / span).clamp(0,1)\n",
        "    return zf.reshape(B,C,T,H,W)\n",
        "\n",
        "def make_viz_for_sample(model, dataset, idx=0, device=\"cpu\", out_dir=\"viz\", make_gif=True):\n",
        "    \"\"\"\n",
        "    Runs a single dataset sample through the model and writes:\n",
        "      - timelapse panels: viz/sample_{idx}.tif\n",
        "      - growth curve:     viz/sample_{idx}_growth.png\n",
        "      - optional GIF:     viz/sample_{idx}.gif\n",
        "    Returns (tiff_path, png_path, gif_path or None)\n",
        "    \"\"\"\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if idx < 0 or idx >= len(dataset):\n",
        "        raise IndexError(f\"idx {idx} out of range for dataset of length {len(dataset)}\")\n",
        "\n",
        "    model.eval()\n",
        "    X, Y, aux, meta = dataset[idx]   # X/Y: [1,T,H,W] torch\n",
        "    with torch.no_grad():\n",
        "        X = X.unsqueeze(0).to(device)  # [1,1,T,H,W]\n",
        "        Y = Y.unsqueeze(0).to(device)  # [1,1,T,H,W]\n",
        "\n",
        "        Xn = _fast_norm_seq_torch(X)\n",
        "        Yn = _fast_norm_seq_torch(Y)\n",
        "\n",
        "        # RNA zeros if needed\n",
        "        if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "            aux_dim = model.rna_mlp[0].in_features\n",
        "            aux = torch.zeros((1, aux_dim), device=device)\n",
        "        else:\n",
        "            aux = None\n",
        "\n",
        "        Pred = model(Xn, rna=aux)  # [1,1,T,H,W]\n",
        "\n",
        "    # to numpy [T,H,W] in [0,1]\n",
        "    x_np = Xn.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
        "    y_np = Yn.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
        "    p_np = Pred.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    tiff_path = out_dir / f\"sample_{idx}.tif\"\n",
        "    png_path  = out_dir / f\"sample_{idx}_growth.png\"\n",
        "\n",
        "    save_timelapse_tiff(x_np, p_np, y_np, tiff_path)\n",
        "    plot_growth_curve(x_np, p_np, y_np, png_path, title=f\"Growth (sample {idx})\")\n",
        "\n",
        "    gif_path = None\n",
        "    if make_gif:\n",
        "        try:\n",
        "            import imageio.v2 as imageio\n",
        "            # stack = tiff.imread(str(tiff_path))  # [T, H, 3W] uint8\n",
        "            stack = np.array(Image.open(str(tiff_path)))\n",
        "            imageio.mimsave(tiff_path.with_suffix(\".gif\"), [frame for frame in stack], duration=0.2)\n",
        "            gif_path = tiff_path.with_suffix(\".gif\")\n",
        "        except Exception as e:\n",
        "            print(f\"[viz] GIF creation skipped: {e}\")\n",
        "\n",
        "    print(f\"[viz] wrote {tiff_path} and {png_path}\" + (f\" and {gif_path}\" if gif_path else \"\"))\n",
        "    return tiff_path, png_path, gif_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vgq7CWGvAy7",
        "outputId": "aeb6f38b-3696-4026-dfb0-4d94d01e552c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[viz] wrote viz/sample_0.tif and viz/sample_0_growth.png and viz/sample_0.gif\n",
            "Outputs: viz/sample_0.tif viz/sample_0_growth.png viz/sample_0.gif\n"
          ]
        }
      ],
      "source": [
        "# Pick a sample, run viz, and get the paths back\n",
        "device_viz = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device_viz)\n",
        "\n",
        "tiff_path, png_path, gif_path = make_viz_for_sample(\n",
        "    model, dataset, idx=0, device=device_viz, out_dir=\"viz\", make_gif=True\n",
        ")\n",
        "print(\"Outputs:\", tiff_path, png_path, gif_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZqTUXaBkwNvH"
      },
      "outputs": [],
      "source": [
        "# ==== Predict + show: input | prediction | ground-truth trajectory ====\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "import torch\n",
        "\n",
        "def _fast_norm_seq_torch(z: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Min/max normalization to [0,1] per-sample across T*H*W.\"\"\"\n",
        "    B,C,T,H,W = z.shape\n",
        "    zf = z.reshape(B, C, -1)\n",
        "    lo = torch.amin(zf, dim=2, keepdim=True)\n",
        "    hi = torch.amax(zf, dim=2, keepdim=True)\n",
        "    span = (hi - lo).clamp_min(1e-6)\n",
        "    zf = ((zf - lo) / span).clamp(0,1)\n",
        "    return zf.reshape(B,C,T,H,W)\n",
        "\n",
        "def _to_uint8(x01: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(x01,0,1).astype(np.float32) * 255.0\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_and_viz_triptych(model, dataset, idx=0, device=None, out_dir=\"viz\",\n",
        "                             sample_every=1, max_cols=16, make_gif=True):\n",
        "    \"\"\"\n",
        "    Produces:\n",
        "      - triptych grid PNG:   viz/triptych_{idx}.png\n",
        "      - multipage panel TIFF viz/triptych_{idx}.tif  (each page: [Input | Pred | GT])\n",
        "      - optional GIF         viz/triptych_{idx}.gif\n",
        "    \"\"\"\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval(); model = model.to(device)\n",
        "\n",
        "    # --- pull sample ---\n",
        "    X, Y, aux, meta = dataset[idx]      # X,Y: [1,T,H,W]\n",
        "    X = X.unsqueeze(0).to(device)       # [1,1,T,H,W]\n",
        "    Y = Y.unsqueeze(0).to(device)       # [1,1,T,H,W]\n",
        "\n",
        "    # normalize like training (fast)\n",
        "    Xn = _fast_norm_seq_torch(X)\n",
        "    Yn = _fast_norm_seq_torch(Y)\n",
        "\n",
        "    # RNA aux (zeros if needed)\n",
        "    if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "        aux_dim = model.rna_mlp[0].in_features\n",
        "        aux_t = torch.zeros((1, aux_dim), device=device)\n",
        "    else:\n",
        "        aux_t = None\n",
        "\n",
        "    # --- predict ---\n",
        "    Pred = model(Xn, rna=aux_t)  # [1,1,T,H,W]\n",
        "\n",
        "    # --- to numpy [T,H,W] in [0,1] ---\n",
        "    x_np = Xn[0,0].detach().cpu().numpy()   # [T,H,W]\n",
        "    y_np = Yn[0,0].detach().cpu().numpy()   # [T,H,W]\n",
        "    p_np = Pred[0,0].detach().cpu().numpy() # [T,H,W]\n",
        "\n",
        "    # --- subsample frames for the grid ---\n",
        "    T = x_np.shape[0]\n",
        "    stride = max(1, sample_every)\n",
        "    cols = min(max_cols, (T + stride - 1) // stride)\n",
        "    sel = list(range(0, T, stride))[:cols]\n",
        "\n",
        "    # --- make a single PNG grid: rows = (Input, Pred, GT), columns = time ---\n",
        "    fig_h = 3.2\n",
        "    fig_w = 1.6 * cols\n",
        "    fig, axes = plt.subplots(3, cols, figsize=(fig_w, fig_h), squeeze=False)\n",
        "    rows = [(\"Input\", x_np), (\"Prediction\", p_np), (\"Ground truth\", y_np)]\n",
        "    for r, (title, arr) in enumerate(rows):\n",
        "        for c, t_idx in enumerate(sel):\n",
        "            ax = axes[r, c]\n",
        "            ax.imshow(arr[t_idx], cmap=\"gray\", vmin=0, vmax=1)\n",
        "            ax.axis(\"off\")\n",
        "            if c == 0:\n",
        "                ax.set_title(title, fontsize=10, pad=4, loc=\"left\")\n",
        "            if r == 0:\n",
        "                ax.set_xlabel(f\"t={t_idx}\", fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    png_path = out_dir / f\"triptych_{idx}.png\"\n",
        "    fig.savefig(png_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # --- multipage TIFF with side-by-side panels per frame: [Input | Pred | GT] ---\n",
        "    tiff_path = out_dir / f\"triptych_{idx}.tif\"\n",
        "    with tiff.TiffWriter(str(tiff_path), bigtiff=True) as tw:\n",
        "        for t in range(T):\n",
        "            panel = np.concatenate([\n",
        "                _to_uint8(x_np[t]),\n",
        "                _to_uint8(p_np[t]),\n",
        "                _to_uint8(y_np[t]),\n",
        "            ], axis=1).astype(np.uint8)  # H x (3W)\n",
        "            tw.write(panel, photometric='minisblack')\n",
        "\n",
        "    # --- optional GIF flipping through time ---\n",
        "    gif_path = None\n",
        "    if make_gif:\n",
        "        try:\n",
        "            import imageio.v2 as imageio\n",
        "            # build frames as wide panels\n",
        "            frames = []\n",
        "            for t in range(T):\n",
        "                panel = np.concatenate([\n",
        "                    _to_uint8(x_np[t]),\n",
        "                    _to_uint8(p_np[t]),\n",
        "                    _to_uint8(y_np[t]),\n",
        "                ], axis=1).astype(np.uint8)\n",
        "                frames.append(panel)\n",
        "            gif_path = out_dir / f\"triptych_{idx}.gif\"\n",
        "            imageio.mimsave(gif_path, frames, duration=0.2)\n",
        "        except Exception as e:\n",
        "            print(f\"[viz] GIF skipped: {e}\")\n",
        "            gif_path = None\n",
        "\n",
        "    print(f\"[viz] wrote:\\n - {png_path}\\n - {tiff_path}\" + (f\"\\n - {gif_path}\" if gif_path else \"\"))\n",
        "    return png_path, tiff_path, gif_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NcSNXaR8wO6d"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "def viz_subset(\n",
        "    model, dataset, indices=None, out_dir=\"viz_subset\",\n",
        "    sample_every=1, max_cols=None, make_gif=False\n",
        "):\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device).eval()\n",
        "\n",
        "    # choose first N if not provided\n",
        "    if indices is None:\n",
        "        N = min(10, len(dataset))  # visualize at most 10\n",
        "        indices = list(range(N))\n",
        "\n",
        "    for j, idx in enumerate(indices):\n",
        "        # fetch once to inspect T\n",
        "        X, Y, *_ = dataset[idx]         # [1,T,H,W] each\n",
        "        T = X.shape[1] if X.ndim == 4 else 1\n",
        "        print(f\"[subset] idx={idx} -> T={T}, HxW={X.shape[-2]}x{X.shape[-1]}\")\n",
        "\n",
        "        # force multiple columns if T>1\n",
        "        mc = max_cols if (max_cols is not None) else (T if T <= 24 else 24)\n",
        "        se = min(sample_every, max(1, T//mc) if mc else 1)\n",
        "\n",
        "        # unique file prefix so nothing gets overwritten\n",
        "        # include idx and T so you can trace what was rendered\n",
        "        prefix = f\"s{idx:04d}_T{T}\"\n",
        "\n",
        "        png_path, tiff_path, gif_path = predict_and_viz_triptych(\n",
        "            model, dataset, idx=idx, device=device, out_dir=out_dir,\n",
        "            sample_every=se, max_cols=mc, make_gif=make_gif,\n",
        "        )\n",
        "\n",
        "        # rename to unique names if function used generic names\n",
        "        pn2  = out_dir / f\"{prefix}__{png_path.name}\"\n",
        "        tf2  = out_dir / f\"{prefix}__{tiff_path.name}\"\n",
        "        png_path.rename(pn2); tiff_path.rename(tf2)\n",
        "        if gif_path:\n",
        "            gf2 = out_dir / f\"{prefix}__{gif_path.name}\"\n",
        "            gif_path.rename(gf2)\n",
        "            print(f\"[viz] wrote: {pn2}, {tf2}, {gf2}\")\n",
        "        else:\n",
        "            print(f\"[viz] wrote: {pn2}, {tf2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64duwia0wqRa",
        "outputId": "71bea912-1c7c-4213-f7ec-e3586056a3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[subset] idx=0 -> T=1, HxW=512x512\n",
            "[viz] wrote:\n",
            " - viz_subset/triptych_0.png\n",
            " - viz_subset/triptych_0.tif\n",
            "[viz] wrote: viz_subset/s0000_T1__triptych_0.png, viz_subset/s0000_T1__triptych_0.tif\n",
            "[subset] idx=1 -> T=1, HxW=512x512\n",
            "[viz] wrote:\n",
            " - viz_subset/triptych_1.png\n",
            " - viz_subset/triptych_1.tif\n",
            "[viz] wrote: viz_subset/s0001_T1__triptych_1.png, viz_subset/s0001_T1__triptych_1.tif\n",
            "[subset] idx=2 -> T=1, HxW=512x512\n",
            "[viz] wrote:\n",
            " - viz_subset/triptych_2.png\n",
            " - viz_subset/triptych_2.tif\n",
            "[viz] wrote: viz_subset/s0002_T1__triptych_2.png, viz_subset/s0002_T1__triptych_2.tif\n",
            "[subset] idx=3 -> T=1, HxW=512x512\n",
            "[viz] wrote:\n",
            " - viz_subset/triptych_3.png\n",
            " - viz_subset/triptych_3.tif\n",
            "[viz] wrote: viz_subset/s0003_T1__triptych_3.png, viz_subset/s0003_T1__triptych_3.tif\n",
            "[subset] idx=4 -> T=1, HxW=512x512\n",
            "[viz] wrote:\n",
            " - viz_subset/triptych_4.png\n",
            " - viz_subset/triptych_4.tif\n",
            "[viz] wrote: viz_subset/s0004_T1__triptych_4.png, viz_subset/s0004_T1__triptych_4.tif\n"
          ]
        }
      ],
      "source": [
        "# visualize first 5 samples, show as many frames as possible (cap to 24 columns)\n",
        "viz_subset(\n",
        "    model, dataset, indices=list(range(5)),\n",
        "    out_dir=\"viz_subset\",\n",
        "    sample_every=1,   # try every frame first\n",
        "    max_cols=None,    # None -> auto use up to 24 columns based on T\n",
        "    make_gif=False    # flip to True later\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "01as7TUHwsFI"
      },
      "outputs": [],
      "source": [
        "# ==== Predict + show: input | prediction | ground-truth trajectory (with contrast stretch) ====\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "import torch\n",
        "\n",
        "def _fast_norm_seq_torch(z: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Min/max normalization to [0,1] per-sample across T*H*W.\"\"\"\n",
        "    B,C,T,H,W = z.shape\n",
        "    zf = z.reshape(B, C, -1)\n",
        "    lo = torch.amin(zf, dim=2, keepdim=True)\n",
        "    hi = torch.amax(zf, dim=2, keepdim=True)\n",
        "    span = (hi - lo).clamp_min(1e-6)\n",
        "    zf = ((zf - lo) / span).clamp(0,1)\n",
        "    return zf.reshape(B,C,T,H,W)\n",
        "\n",
        "def _to_uint8(x01: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(x01,0,1).astype(np.float32) * 255.0\n",
        "\n",
        "def _stretch01(x, lo=2, hi=98):\n",
        "    \"\"\"Percentile-based contrast stretch.\"\"\"\n",
        "    a, b = np.percentile(x, [lo, hi])\n",
        "    return np.clip((x - a) / max(b - a, 1e-6), 0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_and_viz_triptych(model, dataset, idx=0, device=None, out_dir=\"viz\",\n",
        "                             sample_every=1, max_cols=16, make_gif=True):\n",
        "    \"\"\"\n",
        "    Produces:\n",
        "      - PNG grid (Input / Prediction / Ground truth)\n",
        "      - multipage TIFF (per-frame [Input|Pred|GT])\n",
        "      - optional GIF\n",
        "    Applies contrast stretching to prediction frames for better visibility.\n",
        "    \"\"\"\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval(); model = model.to(device)\n",
        "\n",
        "    # --- pull sample ---\n",
        "    X, Y, aux, meta = dataset[idx]      # X,Y: [1,T,H,W]\n",
        "    X = X.unsqueeze(0).to(device)       # [1,1,T,H,W]\n",
        "    Y = Y.unsqueeze(0).to(device)       # [1,1,T,H,W]\n",
        "\n",
        "    # normalize like training (fast)\n",
        "    Xn = _fast_norm_seq_torch(X)\n",
        "    Yn = _fast_norm_seq_torch(Y)\n",
        "\n",
        "    # RNA aux (zeros if needed)\n",
        "    if hasattr(model, \"rna_mlp\") and hasattr(model.rna_mlp[0], \"in_features\"):\n",
        "        aux_dim = model.rna_mlp[0].in_features\n",
        "        aux_t = torch.zeros((1, aux_dim), device=device)\n",
        "    else:\n",
        "        aux_t = None\n",
        "\n",
        "    # --- predict ---\n",
        "    Pred = model(Xn, rna=aux_t)  # [1,1,T,H,W]\n",
        "\n",
        "    # --- to numpy [T,H,W] in [0,1] ---\n",
        "    x_np = Xn[0,0].detach().cpu().numpy()\n",
        "    y_np = Yn[0,0].detach().cpu().numpy()\n",
        "    p_np = Pred[0,0].detach().cpu().numpy()\n",
        "\n",
        "    # --- contrast stretch prediction frames ---\n",
        "    p_np = np.stack([_stretch01(frame, lo=2, hi=98) for frame in p_np], axis=0)\n",
        "\n",
        "    # --- subsample frames for grid ---\n",
        "    T = x_np.shape[0]\n",
        "    stride = max(1, sample_every)\n",
        "    cols = min(max_cols, (T + stride - 1) // stride)\n",
        "    sel = list(range(0, T, stride))[:cols]\n",
        "\n",
        "    # --- PNG grid: rows = (Input, Pred, GT), columns = time ---\n",
        "    fig, axes = plt.subplots(3, cols, figsize=(1.8*cols, 3.2), squeeze=False)\n",
        "    rows = [(\"Input\", x_np), (\"Prediction\", p_np), (\"Ground truth\", y_np)]\n",
        "    for r, (title, arr) in enumerate(rows):\n",
        "        for c, t_idx in enumerate(sel):\n",
        "            ax = axes[r, c]\n",
        "            ax.imshow(arr[t_idx], cmap=\"gray\", vmin=0, vmax=1)\n",
        "            ax.axis(\"off\")\n",
        "            if c == 0:\n",
        "                ax.set_ylabel(title, fontsize=10, labelpad=4)\n",
        "            if r == 0:\n",
        "                ax.set_title(f\"t={t_idx}\", fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    png_path = out_dir / f\"triptych_{idx}_stretched.png\"\n",
        "    fig.savefig(png_path, dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # --- multipage TIFF: [Input|Pred|GT] per frame ---\n",
        "    tiff_path = out_dir / f\"triptych_{idx}_stretched.tif\"\n",
        "    with tiff.TiffWriter(str(tiff_path), bigtiff=True) as tw:\n",
        "        for t in range(T):\n",
        "            panel = np.concatenate([\n",
        "                _to_uint8(x_np[t]),\n",
        "                _to_uint8(p_np[t]),\n",
        "                _to_uint8(y_np[t]),\n",
        "            ], axis=1).astype(np.uint8)\n",
        "            tw.write(panel, photometric='minisblack')\n",
        "\n",
        "    # --- optional GIF ---\n",
        "    gif_path = None\n",
        "    if make_gif:\n",
        "        try:\n",
        "            import imageio.v2 as imageio\n",
        "            frames = []\n",
        "            for t in range(T):\n",
        "                panel = np.concatenate([\n",
        "                    _to_uint8(x_np[t]),\n",
        "                    _to_uint8(p_np[t]),\n",
        "                    _to_uint8(y_np[t]),\n",
        "                ], axis=1).astype(np.uint8)\n",
        "                frames.append(panel)\n",
        "            gif_path = out_dir / f\"triptych_{idx}_stretched.gif\"\n",
        "            imageio.mimsave(gif_path, frames, duration=0.2)\n",
        "        except Exception as e:\n",
        "            print(f\"[viz] GIF skipped: {e}\")\n",
        "\n",
        "    print(f\"[viz] wrote:\\n - {png_path}\\n - {tiff_path}\" + (f\"\\n - {gif_path}\" if gif_path else \"\"))\n",
        "    return png_path, tiff_path, gif_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZuYBRYQy-Wf",
        "outputId": "98753d08-738f-4933-8ee6-3d503931620a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[viz] wrote:\n",
            " - viz_stretched/triptych_0_stretched.png\n",
            " - viz_stretched/triptych_0_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_stretched/triptych_1_stretched.png\n",
            " - viz_stretched/triptych_1_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_stretched/triptych_2_stretched.png\n",
            " - viz_stretched/triptych_2_stretched.tif\n"
          ]
        }
      ],
      "source": [
        "device_viz = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Try first few samples to check visibility\n",
        "for i in range(3):   # visualize 3 examples\n",
        "    predict_and_viz_triptych(\n",
        "        model, dataset, idx=i, device=device_viz,\n",
        "        out_dir=\"viz_stretched\",\n",
        "        sample_every=2,   # show every 2nd frame\n",
        "        max_cols=10,      # up to 10 columns\n",
        "        make_gif=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPl1pl2IzAqs",
        "outputId": "ba8213f3-c0be-434d-91d1-279bc5eea4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([1, 1, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "X, Y, _, _ = dataset[0]\n",
        "print(\"Input shape:\", X.shape)  # expected [1, T, H, W]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJtFFlm04SM",
        "outputId": "f4e78456-228d-4443-d407-5bf35785e370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[viz] wrote:\n",
            " - viz/triptych_0_stretched.png\n",
            " - viz/triptych_0_stretched.tif\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosixPath('viz/triptych_0_stretched.png'),\n",
              " PosixPath('viz/triptych_0_stretched.tif'),\n",
              " None)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_and_viz_triptych(\n",
        "    model, dataset, idx=0,\n",
        "    sample_every=1,    # show every frame\n",
        "    max_cols=20,       # up to 20 columns (frames)\n",
        "    make_gif=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAzP8g_e06LA",
        "outputId": "e086f3e0-2353-4407-958f-850ab352679e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[viz] wrote:\n",
            " - viz/triptych_0_stretched.png\n",
            " - viz/triptych_0_stretched.tif\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosixPath('viz/triptych_0_stretched.png'),\n",
              " PosixPath('viz/triptych_0_stretched.tif'),\n",
              " None)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_and_viz_triptych(\n",
        "    model, dataset, idx=0,\n",
        "    sample_every=1,    # show every frame\n",
        "    max_cols=20,       # allow up to 20 frames side-by-side\n",
        "    make_gif=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l3au99O2a9r",
        "outputId": "d1ac8274-a455-47a5-8d6d-000564473831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[isa] groups: 12 | usable trajectories (>=2 days present): 12\n"
          ]
        }
      ],
      "source": [
        "# --- Parse ISA-Tab and build trajectories compatible with our loaders ---\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to your uploaded file (you said it's /mnt/data/s_OSD-627.txt)\n",
        "ISA_PATH = Path(\"s_OSD-627.txt\")\n",
        "\n",
        "# 1) Read + normalize columns we need\n",
        "df = pd.read_csv(ISA_PATH, sep=\"\\t\", dtype=str).fillna(\"\")\n",
        "\n",
        "# Canonical, shorter column names\n",
        "COL_MAP = {\n",
        "    \"Source Name\": \"source_id\",\n",
        "    \"Sample Name\": \"sample_id\",\n",
        "    \"Factor Value[Spaceflight]\": \"spaceflight\",                    # Ground / Space Flight\n",
        "    \"Factor Value[Growth Environment]\": \"material\",                # SS316, LIS, Silicone, etc.\n",
        "    \"Factor Value[Time]\": \"time\",                                  # 1 / 2 / 3\n",
        "    \"Parameter Value[Sample Media Information]\": \"medium\",         # e.g., LB broth ... KNO3, Cellulose etc.\n",
        "}\n",
        "for old, new in COL_MAP.items():\n",
        "    if old in df.columns:\n",
        "        df.rename(columns={old: new}, inplace=True)\n",
        "\n",
        "# Keep only what we need\n",
        "keep_cols = [\"source_id\", \"sample_id\", \"spaceflight\", \"material\", \"time\", \"medium\"]\n",
        "for c in keep_cols:\n",
        "    if c not in df.columns:\n",
        "        df[c] = \"\"\n",
        "\n",
        "df[\"time_num\"] = pd.to_numeric(df[\"time\"].str.extract(r\"(\\d+)\")[0], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "# 2) Clean/id helpers so we can match TIFF names robustly\n",
        "def clean_id(x: str) -> str:\n",
        "    # Keep alnum + . + _\n",
        "    return re.sub(r\"[^A-Za-z0-9._-]\", \"\", x or \"\").strip()\n",
        "\n",
        "df[\"source_id_clean\"] = df[\"source_id\"].apply(clean_id)\n",
        "df[\"sample_id_clean\"] = df[\"sample_id\"].apply(clean_id)\n",
        "\n",
        "# A flexible set of \"tokens\" that might appear in TIFF filenames\n",
        "def id_tokens(row):\n",
        "    toks = []\n",
        "    if row[\"sample_id_clean\"]:\n",
        "        toks.append(row[\"sample_id_clean\"])\n",
        "    if row[\"source_id_clean\"]:\n",
        "        toks.append(row[\"source_id_clean\"])\n",
        "    # Also common short tokens like \"G1.1\" (prefix of many filenames)\n",
        "    short_source = row[\"source_id_clean\"].split(\"_\")[0]\n",
        "    if short_source and short_source not in toks:\n",
        "        toks.append(short_source)\n",
        "    return toks\n",
        "\n",
        "df[\"tokens\"] = df.apply(id_tokens, axis=1)\n",
        "\n",
        "# 3) Group into trajectories by (spaceflight, material, medium), ordered by time 1→2→3\n",
        "def keyify(s):\n",
        "    return (str(s[\"spaceflight\"]).strip() or \"NA\",\n",
        "            str(s[\"material\"]).strip() or \"NA\",\n",
        "            str(s[\"medium\"]).strip() or \"NA\")\n",
        "\n",
        "trajectories = {}\n",
        "for gkey, gdf in df.groupby(df.apply(keyify, axis=1)):\n",
        "    bucket = {1: [], 2: [], 3: []}\n",
        "    for _, r in gdf.iterrows():\n",
        "        t = int(r[\"time_num\"]) if pd.notna(r[\"time_num\"]) else None\n",
        "        if t in (1, 2, 3):\n",
        "            # store both IDs; downstream will try both when matching TIFFs\n",
        "            bucket[t].append({\n",
        "                \"source_id\": r[\"source_id_clean\"],\n",
        "                \"sample_id\": r[\"sample_id_clean\"],\n",
        "                \"tokens\": r[\"tokens\"],\n",
        "            })\n",
        "    # only keep if at least one day exists\n",
        "    if any(len(v) for v in bucket.values()):\n",
        "        trajectories[gkey] = bucket\n",
        "\n",
        "# Human-friendly flat list of complete (has at least 2 days; prefer 1→2→3) trajectories\n",
        "trajectory_samples = []\n",
        "for gkey, days in trajectories.items():\n",
        "    if sum(1 for d in (1,2,3) if len(days[d])>0) >= 2:\n",
        "        trajectory_samples.append((gkey, days.get(1, []), days.get(2, []), days.get(3, [])))\n",
        "\n",
        "print(f\"[isa] groups: {len(trajectories)} | usable trajectories (>=2 days present): {len(trajectory_samples)}\")\n",
        "\n",
        "# 4) TIFF matching helper — works for both folder-based and zip-based setups\n",
        "\n",
        "def build_name_index_from_folder(tif_paths):\n",
        "    \"\"\"Return a list of searchable names (relative) and a fast lookup string for matching.\"\"\"\n",
        "    # Normalize as posix paths for consistent substring search\n",
        "    names = [str(p).replace(\"\\\\\", \"/\") for p in tif_paths]\n",
        "    return names\n",
        "\n",
        "def build_name_index_from_zip(zip_namelist):\n",
        "    names = [n.replace(\"\\\\\", \"/\") for n in zip_namelist]\n",
        "    # Filter to tiff-like\n",
        "    names = [n for n in names if n.lower().endswith((\".tif\", \".tiff\"))]\n",
        "    return names\n",
        "\n",
        "# Decide which source of TIFF names you have:\n",
        "# - If you have a folder list: set TIFF_NAME_INDEX = build_name_index_from_folder(tif_files)\n",
        "# - If you have a zip namelist: set TIFF_NAME_INDEX = build_name_index_from_zip(tif_files)  # where tif_files came from zf.namelist()\n",
        "\n",
        "TIFF_NAME_INDEX = None  # <-- you must set this after your discovery code runs.\n",
        "\n",
        "def match_tifs_for_ids(id_record, name_index, max_per_id=8):\n",
        "    \"\"\"Given one ISA record {'source_id','sample_id','tokens'}, return all matching TIFF paths (strings).\"\"\"\n",
        "    if name_index is None:\n",
        "        return []\n",
        "    toks = [t for t in id_record.get(\"tokens\", []) if t]\n",
        "    hits = []\n",
        "    for nm in name_index:\n",
        "        nm_lower = nm.lower()\n",
        "        # require every token to appear? Too strict. We'll use \"any token\" match, but prefer stronger matches later.\n",
        "        if any(t.lower() in nm_lower for t in toks):\n",
        "            hits.append(nm)\n",
        "            if len(hits) >= max_per_id:\n",
        "                break\n",
        "    # De-duplicate, keep stable order\n",
        "    out = []\n",
        "    seen = set()\n",
        "    for h in hits:\n",
        "        if h not in seen:\n",
        "            out.append(h); seen.add(h)\n",
        "    return out\n",
        "\n",
        "# 5) Example: build a compact preview of first few trajectories and their TIFF matches (once TIFF_NAME_INDEX is set)\n",
        "def preview_first_n_trajectories(n=3):\n",
        "    if TIFF_NAME_INDEX is None:\n",
        "        print(\"[preview] Please set TIFF_NAME_INDEX after you enumerate TIFF files (folder or zip).\")\n",
        "        return\n",
        "    shown = 0\n",
        "    for gkey, d1, d2, d3 in trajectory_samples:\n",
        "        print(f\"\\nGroup: {gkey}  (days present: {[d for d in (1,2,3) if len({1:d1,2:d2,3:d3}[d])>0]})\")\n",
        "        for day, bucket in ((1,d1),(2,d2),(3,d3)):\n",
        "            if not bucket:\n",
        "                continue\n",
        "            print(f\"  Day {day}:\")\n",
        "            for rec in bucket[:2]:   # show up to 2 records/day\n",
        "                hits = match_tifs_for_ids(rec, TIFF_NAME_INDEX)\n",
        "                print(f\"    ids={rec['source_id']}/{rec['sample_id']}  ->  {len(hits)} tif(s) e.g. {hits[:2]}\")\n",
        "        shown += 1\n",
        "        if shown >= n:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "PR7F56sj3I6J"
      },
      "outputs": [],
      "source": [
        "TIFF_NAME_INDEX = build_name_index_from_zip(tif_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgcc1kQq4UUb",
        "outputId": "925b241d-0708-4e14-c839-d854780541d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Group: ('Ground', 'Cellulose Membrane', 'mAUMg-hi Pi')  (days present: [1, 2, 3])\n",
            "  Day 1:\n",
            "    ids=G2.4/G2.5003  ->  5 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G2.4.tif', 'microscopy/LSDS-55_microscopy_G2.4003.tif']\n",
            "    ids=G2.6/G2.6  ->  2 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G2.6.tif', 'microscopy/LSDS-55_microscopy_G2.6001.tif']\n",
            "  Day 2:\n",
            "    ids=G8.5/G8.5002  ->  2 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G8.5002.tif', 'microscopy/LSDS-55_microscopy_G8.5003.tif']\n",
            "    ids=G8.5/G8.5003  ->  2 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G8.5002.tif', 'microscopy/LSDS-55_microscopy_G8.5003.tif']\n",
            "  Day 3:\n",
            "    ids=G14.5/G14.5002  ->  2 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G14.5002.tif', 'microscopy/LSDS-55_microscopy_G14.5003.tif']\n",
            "    ids=G14.5/G14.5003  ->  2 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G14.5002.tif', 'microscopy/LSDS-55_microscopy_G14.5003.tif']\n",
            "\n",
            "Group: ('Ground', 'Lubricant Impregnated Surface (LIS)', 'LB broth (Lennox) supplemented with KNO3')  (days present: [1, 2, 3])\n",
            "  Day 1:\n",
            "    ids=G2.1/G2.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G2.1.tif', 'microscopy/LSDS-55_microscopy_G2.1001.tif']\n",
            "    ids=G2.1/G2.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G2.1.tif', 'microscopy/LSDS-55_microscopy_G2.1001.tif']\n",
            "  Day 2:\n",
            "    ids=G8.1/G8.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G8.1.tif', 'microscopy/LSDS-55_microscopy_G8.1001.tif']\n",
            "    ids=G8.1/G8.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G8.1.tif', 'microscopy/LSDS-55_microscopy_G8.1001.tif']\n",
            "  Day 3:\n",
            "    ids=G14.1/G14.1001  ->  3 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G14.1001.tif', 'microscopy/LSDS-55_microscopy_G14.1002.tif']\n",
            "    ids=G14.1/G14.1002  ->  3 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G14.1001.tif', 'microscopy/LSDS-55_microscopy_G14.1002.tif']\n",
            "\n",
            "Group: ('Ground', 'Passivated SS316', 'LB broth (Lennox) supplemented with KNO3')  (days present: [1, 2, 3])\n",
            "  Day 1:\n",
            "    ids=G1.5/G1.5  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G1.5.tif', 'microscopy/LSDS-55_microscopy_G1.5001.tif']\n",
            "    ids=G1.5/G1.5001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G1.5.tif', 'microscopy/LSDS-55_microscopy_G1.5001.tif']\n",
            "  Day 2:\n",
            "    ids=G7.5/G7.5  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G7.5.tif', 'microscopy/LSDS-55_microscopy_G7.5001.tif']\n",
            "    ids=G7.5/G7.5001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G7.5.tif', 'microscopy/LSDS-55_microscopy_G7.5001.tif']\n",
            "  Day 3:\n",
            "    ids=G13.5/G13.5  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G13.5.tif', 'microscopy/LSDS-55_microscopy_G13.5001.tif']\n",
            "    ids=G13.5/G13.5001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G13.5.tif', 'microscopy/LSDS-55_microscopy_G13.5001.tif']\n",
            "\n",
            "Group: ('Ground', 'SS316', 'LB broth (Lennox) supplemented with KNO3')  (days present: [1, 2, 3])\n",
            "  Day 1:\n",
            "    ids=G1.1/G1.1  ->  3 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G1.1.tif', 'microscopy/LSDS-55_microscopy_G1.1002.tif']\n",
            "    ids=G1.1/G1.1001  ->  3 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G1.1.tif', 'microscopy/LSDS-55_microscopy_G1.1002.tif']\n",
            "  Day 2:\n",
            "    ids=G7.1/G7.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G7.1.tif', 'microscopy/LSDS-55_microscopy_G7.1001.tif']\n",
            "    ids=G7.1/G7.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G7.1.tif', 'microscopy/LSDS-55_microscopy_G7.1001.tif']\n",
            "  Day 3:\n",
            "    ids=G13.1/G13.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G13.1.tif', 'microscopy/LSDS-55_microscopy_G13.1001.tif']\n",
            "    ids=G13.1/G13.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G13.1.tif', 'microscopy/LSDS-55_microscopy_G13.1001.tif']\n",
            "\n",
            "Group: ('Ground', 'Silicone', 'mAUMg-hi Pi')  (days present: [1, 2, 3])\n",
            "  Day 1:\n",
            "    ids=G3.2/G3.2  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G3.2.tif', 'microscopy/LSDS-55_microscopy_G3.2001.tif']\n",
            "    ids=G3.2/G3.2001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G3.2.tif', 'microscopy/LSDS-55_microscopy_G3.2001.tif']\n",
            "  Day 2:\n",
            "    ids=G9.1/G9.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G9.1.tif', 'microscopy/LSDS-55_microscopy_G9.1001.tif']\n",
            "    ids=G9.1/G9.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G9.1.tif', 'microscopy/LSDS-55_microscopy_G9.1001.tif']\n",
            "  Day 3:\n",
            "    ids=G15.1/G15.1  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G15.1.tif', 'microscopy/LSDS-55_microscopy_G15.1001.tif']\n",
            "    ids=G15.1/G15.1001  ->  4 tif(s) e.g. ['microscopy/LSDS-55_microscopy_G15.1.tif', 'microscopy/LSDS-55_microscopy_G15.1001.tif']\n"
          ]
        }
      ],
      "source": [
        "preview_first_n_trajectories(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgdHzJVc4WDD",
        "outputId": "45f1a413-68dc-4749-ab76-25d208aae1ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Viz samples: 10\n",
            "X: torch.Size([1, 2, 256, 256]) Y: torch.Size([1, 2, 256, 256]) meta: {'key': ('Ground', 'Cellulose Membrane', 'mAUMg-hi Pi'), 'days': [1, 2, 3], 't0': 0, 'T': 2}\n",
            "[viz] wrote:\n",
            " - viz_trajectories/triptych_0_stretched.png\n",
            " - viz_trajectories/triptych_0_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_trajectories/triptych_1_stretched.png\n",
            " - viz_trajectories/triptych_1_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_trajectories/triptych_2_stretched.png\n",
            " - viz_trajectories/triptych_2_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_trajectories/triptych_3_stretched.png\n",
            " - viz_trajectories/triptych_3_stretched.tif\n",
            "[viz] wrote:\n",
            " - viz_trajectories/triptych_4_stretched.png\n",
            " - viz_trajectories/triptych_4_stretched.tif\n"
          ]
        }
      ],
      "source": [
        "# ==== Build a visualization dataset from your trajectories + tif_map, then render ====\n",
        "import numpy as np, torch\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "\n",
        "# --- helper: reduce TIFF arrays to a single 2D frame for that \"day\"\n",
        "def _to_frame2d(arr):\n",
        "    a = np.asarray(arr)\n",
        "    if a.ndim == 2:\n",
        "        return a.astype(np.float32)\n",
        "    a = np.squeeze(a)\n",
        "    if a.ndim == 2:\n",
        "        return a.astype(np.float32)\n",
        "    if a.ndim == 3:\n",
        "        # If [T,H,W] or [Z,H,W], use mean projection (change to [0], max, etc. if you prefer)\n",
        "        return a.mean(axis=0).astype(np.float32)\n",
        "    # fallback: try flatten-wise reshape to last two dims\n",
        "    return a.reshape(a.shape[-2], a.shape[-1]).astype(np.float32)\n",
        "\n",
        "# --- helper: pick the first tif that is actually present in tif_map (keys by basename)\n",
        "def _pick_tif_for_idrecord(id_record, tif_map, name_index=None):\n",
        "    # id_record contains \"tokens\" you built earlier\n",
        "    tokens = [t.lower() for t in id_record.get(\"tokens\", []) if t]\n",
        "    if not tokens:\n",
        "        return None\n",
        "    # check available basenames in tif_map\n",
        "    for k in tif_map.keys():\n",
        "        stem = Path(k).stem.lower()\n",
        "        if any(t in stem for t in tokens):\n",
        "            return k\n",
        "    # optionally fall back to name_index (zip/folder namelist) then map to basename\n",
        "    if name_index:\n",
        "        for nm in name_index:\n",
        "            stem = Path(nm).stem.lower()\n",
        "            if any(t in stem for t in tokens):\n",
        "                base = Path(nm).name\n",
        "                if base in tif_map:\n",
        "                    return base\n",
        "    return None\n",
        "\n",
        "class TrajectoryVizDataset(Dataset):\n",
        "    \"\"\"\n",
        "    One sample per (spaceflight, material, medium) trajectory with >=3 days.\n",
        "    X: [1, T_win, H, W] (e.g., days [d1, d2])\n",
        "    Y: [1, T_win, H, W] (e.g., days [d2, d3])\n",
        "    \"\"\"\n",
        "    def __init__(self, trajectories, tif_map, tiff_name_index=None, T_win=2):\n",
        "        self.samples = []     # list of dicts with: key, days, frames2d\n",
        "        self.T_win = T_win\n",
        "        self.tif_map = tif_map\n",
        "\n",
        "        for gkey, days_dict in trajectories.items():\n",
        "            # collect ordered (day, frame2d) with one representative frame per day\n",
        "            ordered = []\n",
        "            for d in sorted([d for d in (1,2,3) if d in days_dict]):\n",
        "                bucket = days_dict[d]\n",
        "                if not bucket:\n",
        "                    continue\n",
        "                # choose first resolvable tif from this day's ids\n",
        "                chosen = None\n",
        "                for rec in bucket:\n",
        "                    tk = _pick_tif_for_idrecord(rec, tif_map, name_index=tiff_name_index)\n",
        "                    if tk is not None:\n",
        "                        chosen = tk\n",
        "                        break\n",
        "                if chosen is None:\n",
        "                    continue\n",
        "                frame = _to_frame2d(tif_map[chosen])\n",
        "                ordered.append((d, frame))\n",
        "            if len(ordered) < (self.T_win + 1):\n",
        "                continue\n",
        "\n",
        "            # enforce common HxW within this group\n",
        "            # choose most frequent size\n",
        "            sizes = {}\n",
        "            for _, fr in ordered:\n",
        "                sizes[fr.shape] = sizes.get(fr.shape, 0) + 1\n",
        "            ref = max(sizes.items(), key=lambda kv: kv[1])[0]\n",
        "            ordered = [(d, fr) for (d, fr) in ordered if fr.shape == ref]\n",
        "            if len(ordered) < (self.T_win + 1):\n",
        "                continue\n",
        "\n",
        "            # build sliding windows over days (for 3 days and T_win=2 → exactly one window)\n",
        "            frames = [fr for (_, fr) in ordered]\n",
        "            daylist = [d for (d, _) in ordered]\n",
        "            T = len(frames)\n",
        "            for t0 in range(0, T - self.T_win):\n",
        "                if t0 + self.T_win >= T:\n",
        "                    break\n",
        "                self.samples.append({\n",
        "                    \"key\": gkey,\n",
        "                    \"days\": daylist[t0 : t0 + self.T_win + 1],  # e.g., [1,2,3]\n",
        "                    \"frames\": frames,   # keep full to slice on getitem\n",
        "                    \"t0\": t0\n",
        "                })\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        t0 = s[\"t0\"]; T_win = self.T_win\n",
        "        frames = s[\"frames\"]\n",
        "        X = np.stack(frames[t0 : t0 + T_win], axis=0)           # [T_win,H,W] (e.g., Day1, Day2)\n",
        "        Y = np.stack(frames[t0 + 1 : t0 + 1 + T_win], axis=0)   # [T_win,H,W] (e.g., Day2, Day3)\n",
        "        X = torch.from_numpy(X)[None, ...]  # [1,T,H,W]\n",
        "        Y = torch.from_numpy(Y)[None, ...]\n",
        "        meta = {\"key\": s[\"key\"], \"days\": s[\"days\"], \"t0\": t0, \"T\": T_win}\n",
        "        return X, Y, None, meta\n",
        "\n",
        "# --- Build the viz dataset from the trajectories you already have\n",
        "# trajectories: { (sf,mat,med): {1:[idrecs], 2:[...], 3:[...]} }\n",
        "# tif_map: {basename -> np.ndarray}\n",
        "# If you have a zip/folder name index, pass it as tiff_name_index; otherwise omit.\n",
        "viz_dataset = TrajectoryVizDataset(trajectories, tif_map, tiff_name_index=TIFF_NAME_INDEX, T_win=2)\n",
        "print(\"Viz samples:\", len(viz_dataset))\n",
        "if len(viz_dataset) > 0:\n",
        "    X, Y, _, m = viz_dataset[0]\n",
        "    print(\"X:\", X.shape, \"Y:\", Y.shape, \"meta:\", m)\n",
        "\n",
        "# --- Render a few samples with your stretched triptych visualizer ---\n",
        "device_viz = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device_viz).eval()\n",
        "\n",
        "for i in range(min(5, len(viz_dataset))):\n",
        "    try:\n",
        "        predict_and_viz_triptych(\n",
        "            model, viz_dataset, idx=i, device=device_viz,\n",
        "            out_dir=\"viz_trajectories\", sample_every=1, max_cols=8, make_gif=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"[viz] sample {i} skipped: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wo9y6Ll4vfv",
        "outputId": "2ee64844-c97b-4b76-e58b-576c4f3362dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[viz] wrote:\n",
            " - viz_trajectories_bright/triptych_0_stretched.png\n",
            " - viz_trajectories_bright/triptych_0_stretched.tif\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosixPath('viz_trajectories_bright/triptych_0_stretched.png'),\n",
              " PosixPath('viz_trajectories_bright/triptych_0_stretched.tif'),\n",
              " None)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_and_viz_triptych(\n",
        "    model, viz_dataset, idx=0,\n",
        "    out_dir=\"viz_trajectories_bright\",\n",
        "    sample_every=1, max_cols=8,\n",
        "    make_gif=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiCkWlfX5fkH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
